{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-Context Learning\n",
    "\n",
    "The Universal API also opens up an interesting possibility\n",
    "- Can we use a Large Language Model\n",
    "- To solve a new Target task\n",
    "- *without* further training (i.e., Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On a pure syntax level, this is feasible\n",
    "- all problems are instances of \"predict the next\"\n",
    "- perhaps the LLM's text completion power *also* captures domain-specific knowledge\n",
    "    - the completion is related to the domain-specific words of the prompt\n",
    "    - for example, if the prompt is in French, the completion would be expected to be in French too\n",
    "\n",
    "So the possibility is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But how does the Source LLM discern what the Target task is ?\n",
    "\n",
    "The answer\n",
    "- we provide demonstrations (*examplars*) of the new task as part of the *Context*\n",
    "    - demonstrating the relationship between Input and Output\n",
    "    - as the initial part of the prompt\n",
    "- and present the Input for a test example as the final part of the prompt\n",
    "    - no output\n",
    "    - hope \"predict the next\" will result in the correct Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, we can describe Translation between languages with the following Context $C$\n",
    "\n",
    "    Translate English to French\n",
    "    \n",
    "    sea otter =>  loutre de mer\n",
    "    \n",
    "    peppermint => menthe poivree\n",
    "    \n",
    "    plush giraffe => girafe peluche\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "   \n",
    "The expectation is that when the user presents the prompt $\\x$\n",
    "\n",
    "         cheese => \n",
    "         \n",
    "the model will respond with the French translation of `cheese`.\n",
    "- the \"next words\" predicted by the Language Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The idea behind *In-Context Learning* is to\n",
    "- condition the Pre-Trained Language Model (Source LLM)\n",
    "- to complete the prompt of a new Target Task\n",
    "- with the correct response for the Target Task\n",
    "- **without** further training (Fine-Tuning)\n",
    "- merely by providing the examples that demonstrate the behavior of the new Target task\n",
    "- **as parts of the prompt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The examples demonstrating the Target task are called *exemplars*.\n",
    "- each exemplar is provided as a prompt and response pair, as per the Universal API\n",
    "$$\\langle \\x^\\ip, \\y^\\ip \\rangle = \\langle \\text{prompt}, \\text{response} \\rangle$$\n",
    "\n",
    "To predict the response for a new prompt $\\x$\n",
    "- the exemplars are concatenated together (the *Context* $C$)\n",
    "- the Context is a demonstration of the Target Task's relationship between features and label\n",
    "\n",
    "The new prompt $\\x$ is appended to the Context\n",
    "- the Pre-Trained model is expected to complete the prompt\n",
    "- by providing a response specific to the Target task and the prompt $\\x$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More formally: \n",
    "- Let $C$ (\"context\") denote the pre-prompt.\n",
    "- Let $\\x$ denote the \"query\" (e.g., `cheese =>`)\n",
    "\n",
    "The unconditional Language Modeling objective\n",
    "$$\n",
    "\\pr{\\y | \\x}\n",
    "$$\n",
    "is to create the sequence $\\y$ that follows the sequence of prompt $\\x$.\n",
    "\n",
    "Here, the pre-prompt conditions the model's objective\n",
    "$$\n",
    "\\pr{\\y | C, \\x }\n",
    "$$\n",
    "to create the sequence $\\y$ that follows from the exemplars $C$ and prompt $\\x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is just a mechanical process\n",
    "- create the sequence $\\dot \\x$\n",
    "- by concatenating some number $k$ of exemplars: $\\langle \\x^{(1)}, \\y^{(1)} \\rangle, \\ldots, \\langle \\x^{(k)}, \\y^{(k)} \\rangle $\n",
    "- and  prompt string $\\x$\n",
    "- delimiting elements by separator characters $\\langle \\text{SEP}_1 \\rangle. \\langle \\text{SEP}_2 \\rangle$\n",
    "\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\dot \\x = \\text{concat} (  & \\x^{(1)}, \\langle \\text{SEP}_1 \\rangle, \\y^{(1)}, \\langle \\text{SEP}_2 \\rangle,  \\\\\n",
    "              &   \\vdots \\\\\n",
    "              &   \\x^{(k)}, \\langle \\text{SEP}_1 \\rangle, \\y^{(k)}, \\langle \\text{SEP}_2 \\rangle, \\\\\n",
    "              &   \\x \\\\\n",
    "              & ) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The LLM then computes\n",
    "$$\n",
    "\\pr{ \\y | \\dot \\x }\n",
    "$$\n",
    "\n",
    "For convenience, we will just write this as the conditional probability\n",
    "$$\n",
    "\\pr{\\y | \\x,  C}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-Context learning: let's experiment\n",
    "\n",
    "The [HuggingFace platform](https://huggingface.co/) has libraries of pre-trained models for many tasks, including Language models.\n",
    "\n",
    "There is a clean API for using these models in code (I recommend their on-line [course](https://huggingface.co/) if you want to play with it).\n",
    "\n",
    "But they also host many of their models for interactive use.\n",
    "\n",
    "This is valuable not just for the obvious reason of ease of use\n",
    "- some models are too big to load on the machines available to us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Note**\n",
    "\n",
    "These calls of the form\n",
    "    \n",
    "    URL w/?text=....\n",
    "may no longer work, or may require logging in to HuggingFace.\n",
    "\n",
    "We will show a notebook below where these examples are run using a programming API.\n",
    "\n",
    "\n",
    "For fun, let's try using In-Context learning in order to get a Pre-Trained Language model to\n",
    "classify whether a short movie review is positive or negative.\n",
    "\n",
    "[Movie review sentiment: few shot learning GPT-2](https://huggingface.co/gpt2?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "[Movie review sentiment: few shot learning GPT-J 6B](https://huggingface.co/EleutherAI/gpt-j-6B?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "[Movie review sentiment: few shot learning:gpt-neox-20b](https://huggingface.co/EleutherAI/gpt-neox-20b?text=this+movie+was+great%3A+positive%0A%0A+one+of+the+best+films+of+the+year%3A+positive+%0A%0Ajust+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0Athis+movie+was+great%3A+positive+%0A%0Aone+of+the+best+films+of+the+year%3A+positive+%0A%0A+just+plain+awful%3A+negative+%0A%0AI+would+not+see+this+one+again%3A+negative+%0A%0AI+am+disturbed+by+this+film%3A)\n",
    "\n",
    "You can try cutting and pasting the prompt into the hosted inference instance of other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can play with In-Context learning by going to the page of a model and typing into the *Hosted Inference API* text box.\n",
    "\n",
    "But there is also an API that allows you to pass the input (context plus prompt) via a URL.\n",
    "\n",
    "If you click on the `Deploy` button and choose the `Inference API` drop-down\n",
    "- you will see Python code for querying the model programaticly.\n",
    "\n",
    "<img src=\"images/hf_inference_api_code.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Please note\n",
    "- our toy example above used a *single* test example\n",
    "- even if we manage to get a correct prediction on a single example\n",
    "    - we don't have confidence that the new task was successfully learned !\n",
    "    - we really should evaluate success on a larger number of text examples\n",
    "- still: the fact that the exemplars taught the model the correct syntax for an answer is exciting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is a very crude notebook that uses the HuggingFace inference API to experiment with in-context learning.\n",
    "\n",
    "- [Experiment in In context learning: Colab](https://colab.research.google.com/github/kenperry-public/ML_Advanced_Fall_2024/blob/master/HF_inference_play.ipynb)\n",
    "- [Experiment in In context learning: local](HF_inference_play.ipynb)\n",
    "\n",
    "<!--- #include (HF_inference_play.ipynb) --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our new Target task is movie reviews.\n",
    "\n",
    "Here are the exemplars we will use\n",
    "\n",
    "        exemplars = [ \"this movie was great: positive\",\n",
    "                     \"one of the best films of the year: positive\",\n",
    "                     \"just plain awful: negative\",\n",
    "                     \"I would not see this one again: negative\",\n",
    "                     \"this movie was great: positive\",\n",
    "                     \"one of the best films of the year: positive\",\n",
    "                     \"just plain awful: negative\",\n",
    "                     \"I would not see this one again: negative\",\n",
    "                     \"I love this film: positive\"\n",
    "]\n",
    "\n",
    "Not the greatest exemplars (too short), but we just want to illustrate the idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want the model to classify the following review as poistive/negative\n",
    "\n",
    "    \"I've heard not so great things about this one:\"\n",
    "    \n",
    "We would hope the exemplars are sufficient to cause the \"predict the next\" task to generate\n",
    "the continuation\n",
    "\n",
    "    negative\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will use a relatively small (20B parameters) LLM.\n",
    "\n",
    "Here are the results\n",
    "\n",
    "        [0.22 seconds, using EleutherAI/gpt-neox-20b]\n",
    "         this movie was great: positive \n",
    "         one of the best films of the year: positive \n",
    "         just plain awful: negative \n",
    "         I would not see this one again: negative \n",
    "         this movie was great: positive \n",
    "         one of the best films of the year: positive \n",
    "         just plain awful: negative \n",
    "         I would not see this one again: negative \n",
    "         I love this film: positive \n",
    "         I've heard not so great things about this one: negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Negative ! Just as we had hoped.\n",
    "\n",
    "However, the exemplars are not ideal.  The LLM continues *beyond* the classification and\n",
    "further generates more reviews !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "         it is entertaining: positive \n",
    "         I would not see this one again: negative \n",
    "         I love this film: positive \n",
    "         I've heard not so great things: negative \n",
    "         it is entertaining: positive \n",
    "         I've heard not so great things: negative \n",
    "         enchanced by slow motion visuals: positive \n",
    "         excellent: positive \n",
    "         terrific sound design in this one too: positive \n",
    "         Stallone is a great actor: positive \n",
    "         I'd turn down a free trip to London to see this movie:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Obviously, our exemplars did not fully convey our intent.\n",
    "\n",
    "Creating a prompt (context) that will cause an LLM to do *exactly* what you want\n",
    "- is an art\n",
    "- called Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning to learn\n",
    "\n",
    "Does In-Context learning really work ?\n",
    "\n",
    "We can begin to answer this question by\n",
    "- examining the behavior of a Pre-Trained LLM\n",
    "- on a new task\n",
    "- using $k$ exemplars\n",
    "    - varying $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Depending on $k$, we refer to the behavior of the LLM by slightly different names\n",
    "- **Few shot learning**: $10 \\le k \\le 100$ typically\n",
    "- **One shot learning**: $k = 1$\n",
    "- **Zero shot learning** $k=0$\n",
    "\n",
    "A picture will help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Few/One/Zero shot learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_Few_Shot_Training.png\"\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf</center></td>\n",
    "    </tr>   \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is this even possible ?!   Learning a new task with **zero** exemplars ?\n",
    "\n",
    "Let's look at the reported In-Context Learning results of 3 LLM's of varying size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Few/One/Zero shot learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_Few_Shot_Accuracy.png\"\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf#page=4</center></td>\n",
    "    </tr>   \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A couple of observations\n",
    "- As the size of the model grows: In-Context Learning behavior improves\n",
    "    - compare the 175 Billion parameter model to the smaller models\n",
    "    - we sometimes refer to this as behavior that \"emerges\" only when a model is sufficiently large\n",
    "- More exemplars (greater $k$) helps\n",
    "    - but not much for the smallest model\n",
    "\n",
    "- Zero shot learning works !\n",
    "    - but this is a behavior that only emerges for very large models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# \"Fine-tuning\" a model with In-Context Learning\n",
    "\n",
    "\"Fine-tuning\" (Transfer Learning) refers to\n",
    "- adapting a model for a Source Task\n",
    "- to be able to perform a Target Task\n",
    "\n",
    "Usually\n",
    "- this means training a pre-trained model (Source Task)\n",
    "- with a small number of examples of the Target Task\n",
    "- causing the model's weights to adapt to the Target Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But In-Context Learning\n",
    "- adapts a model for the Source Task\n",
    "- to be able to solve the Target Task\n",
    "- **without** changing the model's weights\n",
    "\n",
    "So this may be an alternative method of Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
