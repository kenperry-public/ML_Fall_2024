{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<html>\n",
    "<p style=\"font-size:32px\"><strong>Classical Machine Learning</strong></p>\n",
    "</html>\n",
    "\n",
    "<html>\n",
    "<p style=\"font-size:26px\"><strong>Week 0</strong></p>\n",
    "</html>\n",
    " \n",
    "\n",
    "**Plan**\n",
    "- Setting up your learning and programming environment\n",
    "\n",
    "\n",
    "**Getting started**\n",
    "- [Setting up your ML environment](Setup_NYU.ipynb)\n",
    "    - [Choosing an ML environment](Choosing_an_ML_Environment_NYU.ipynb)\n",
    "- [Quick intro to the tools](Getting_Started.ipynb)\n",
    "\n",
    "<!--- #include (README.md) --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 1\n",
    "**Plan**\n",
    "- Motivate Machine Learning\n",
    "- Introduce notation used throughout course\n",
    "- Plan for initial lectures\n",
    "    - *What*: Introduce, motivate a model\n",
    "    - *How*:  How to use a model: function signature, code (API)\n",
    "    - *Why*:  Mathematical basis -- enhance understanding and ability to improve results\n",
    "\n",
    "        \n",
    "- [Course Overview](Course_overview_NYU.ipynb)\n",
    "- [Machine Learning: Overview](ML_Overview.ipynb)\n",
    "- [Intro to Classical ML](Intro_Classical_ML.ipynb)\n",
    "\n",
    "## Using an AI Assistant\n",
    "\n",
    "AI Assistants are often very good at coding.\n",
    "\n",
    "But using one to just \"get the answer\" deprives you of a valuable tool\n",
    "- you can ask the Assistant *why* it chose to do something\n",
    "- keep on asking\n",
    "- treat it as a private tutor !\n",
    "\n",
    "[Learning about KNN using an Assistant as a private tutor](https://www.perplexity.ai/search/using-python-and-sklearn-pleas-407oe3uzTXu1i9xEHVR2MQ)\n",
    "- [Code answer from Assistant](KNN_illustration_Perplexity.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 2\n",
    "\n",
    "**Recap of last week**\n",
    "\n",
    "- [Summary of Intro to Supervised Machine Learning](Intro_to_Supervised_Learning_Summary.ipynb)\n",
    "\n",
    "**Plan**\n",
    "\n",
    "We will learn the Recipe for Machine Learning,  a disciplined approach to solving problems in Machine Learning.\n",
    "\n",
    "We will illustrate the Recipe while, at the same time,\n",
    "introducing a model for the Regression task: Linear Regression.\n",
    "W\n",
    "Our coverage of the Recipe will be rapid and shallow (we use an extremely simple example for illustration).\n",
    "\n",
    "I highly recommend reviewing and understanding\n",
    "this [Geron notebook](external/handson-ml2/02_end_to_end_machine_learning_project.ipynb)\n",
    "in order to acquire a more in-depth appreciation of the Recipe.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Recipe for Machine Learning</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/W1_L3_S4_ML_Process.png\" width=\"100%\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "**Recipe, as illustrated by Linear Regression**\n",
    "\n",
    "[The Recipe for Machine Learning: Solving a Regression task](Recipe_via_Linear_Regression.ipynb)\n",
    "- A *process* for Machine Learning\n",
    "    - Go through the methodical, multi-step process\n",
    "        - Quick first pass, followed by Deeper Dives\n",
    "     \n",
    "**Fitting a model: details**\n",
    "\n",
    "Recall: fitting a model (finding optimal value for the parameters) is found by minimizing a Loss function.\n",
    "\n",
    "Let's examine a typical Loss function for Regression\n",
    "- [Regression: Loss Function](Linear_Regression_Loss_Function.ipynb)\n",
    "\n",
    "**Iterative training: when to stop**\n",
    "\n",
    "Increasing the number of parameters of a model improves in-sample fit (reduces Loss) but may compromise\n",
    "out-of-sample prediction (generalization).\n",
    "\n",
    "We examine the issues of having too many/too few parameters.\n",
    "- [When to stop iterating: Bias and Variance](Bias_and_Variance.ipynb)\n",
    "\n",
    "**Get the data: Fundamental Assumption of Machine Learning**\n",
    "\n",
    "- [Getting *good* training examples](Recipe_Training_data.ipynb)\n",
    "\n",
    "**Regression: final thoughts (for now)**\n",
    "\n",
    "- [Regression: coda](Regression_coda.ipynb)\n",
    "\n",
    "\n",
    "**Transformations**\n",
    " - [Prepare Data: Intro to Transformations](Prepare_data_Overview.ipynb)\n",
    " \n",
    "**Deeper dives**\n",
    "- [Fine tuning techniques](Fine_tuning.ipynb)\n",
    "\n",
    "## Using an AI Assistant\n",
    "\n",
    "[Learning about Linear Regression using an Assistant as private tutor](https://www.perplexity.ai/search/using-python-sklearn-and-matpl-vTYy7oGdRQ6upR5L5OSjrg)\n",
    "- [Code Answer from Assistant](LinearRegression_Illustration_Perplexity.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification Task\n",
    "\n",
    "**Plan**\n",
    "- We introduce a model for the Classification task: Logistic Regression\n",
    "- How to deal with Categorical (non-numeric) variables\n",
    "    - classification target\n",
    "    - features\n",
    "\n",
    "**Classification intro**\n",
    "- [Classification: Overview](Classification_Overview.ipynb)\n",
    "- [Classification and Categorical Variables](Classification_Notebook_Overview.ipynb)\n",
    "    - [linked notebook](Classification_and_Non_Numerical_Data.ipynb)\n",
    "\n",
    "**Deeper dives**\n",
    "- [Log odds](Classification_Log_Odds.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 3\n",
    "\n",
    "**Plan**\n",
    "\n",
    "Continue with the Classification Task, following the Recipe for Machine Learning.\n",
    "\n",
    "We then examine the proper treatment of categorical variables (target or feature).\n",
    "\n",
    "Along the way, we run into a subtle difficulty: the Dummy Variable Trap.\n",
    "\n",
    "We then generalize Binary Classification into classification into more than two classes.\n",
    "\n",
    "**Classification, continued**\n",
    "\n",
    "We begin with review the Exploratory Data Analysis step that we introduced last week.\n",
    "\n",
    "- [Classification and Categorical Variables: Visualize the data](Classification_Notebook_Overview.ipynb#Visualize-Data-to-gain-insights)\n",
    "\n",
    "**Categorical variables** (contained as subsections of Classification and Categorical Variables)\n",
    "\n",
    "- [Classification and Categorical Variables: Categorical Variables](Classification_Notebook_Overview.ipynb#Categorical-variables)\n",
    "    - [Categorical variables, One Hot Encoding (OHE)](Categorical_Variables.ipynb)\n",
    "    \n",
    "**Multinomial Classification**\n",
    "\n",
    "- [Multinomial Classification](Multinomial_Classification.ipynb)\n",
    "\n",
    "**Classification and Categorical variables wrapup**\n",
    "\n",
    "- [Classification Loss Function](Classification_Loss_Function.ipynb)\n",
    "- [Baseline model for Classification](Classification_Baseline_Model.ipynb)\n",
    "- [Using pipelines to avoid cheating in cross validation](Prepare_data_Overview.ipynb#Using-pipelines-to-avoid-cheating-in-cross-validation)\n",
    "- [OHE issue: Dummy variable trap](Dummy_Variable_Trap.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "**Classification: final thoughts (for now)**\n",
    "\n",
    "- [Classification: coda](Classification_coda.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignments\n",
    "\n",
    "Your assignments should follow the [Assignment Guidelines](assignments/Assignment_Guidelines.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
