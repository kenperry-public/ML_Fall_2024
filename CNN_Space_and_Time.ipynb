{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "\\newcommand{idxb}{\\mathbf{i}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( {#1} \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\kernel}{\\mathbf{k}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Layers: Space and Time\n",
    "\n",
    "In our introductory examples\n",
    "- The non-feature dimension of output $\\y_\\llp$\n",
    "- Is identical to the non-feature dimension of input $\\y_{(\\ll-1)}$\n",
    "\n",
    "There are different choices we can make when \"sliding\" the kernel over the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These choices impact\n",
    "- The size of the non-feature dimension of the output\n",
    "- And, in turn, the time requirements of subsequent layers (because of the size)\n",
    "\n",
    "Let's do some quick calculations and then show choices for controlling the space consumed by $y_\\llp$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNN Math: Time versus number of parameters\n",
    "\n",
    "In designing a Neural Network we are confronted with choices\n",
    "- how many layers\n",
    "- width (number of features) at each layer\n",
    "\n",
    "When Convolutional layers are included, there are additional choices\n",
    "- size $f$ of filter\n",
    "- increment with which we slide the kernel over the non-feature dimensions locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the absence of a science defined optimal values for the choices\n",
    "- we resort to empirical studies\n",
    "- treat the choices as hyper-parameters\n",
    "- establish a Performance Metric and a set of Benchmark examples\n",
    "- examine the trade-off between Performance Metric and hyper-parameter choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One element in the trade-off involves external costs\n",
    "- amount of space (memory)\n",
    "- amount of time\n",
    "\n",
    "We explore these costs in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider input layer $(\\ll-1)$ with \n",
    "- $N$ non-feature dimensions\n",
    "- $n_{(\\ll-1)}$ feature maps/channels\n",
    "$$\n",
    "|| \\y_{(\\ll-1)} || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_{(\\ll-1)} )\n",
    "$$\n",
    "\n",
    "Layer $\\ll$ will apply a Convolution that preserves the non-feature dimensions\n",
    "$$\n",
    "|| \\y_\\llp || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_\\llp )\n",
    "$$\n",
    "\n",
    "For simplicity of presentation: consider the case when $N=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How many weights/parameters does layer $\\ll$ consume (i.e, what is size of $\\W_\\llp$ ) ?\n",
    "- Each kernel $\\kernel_{\\llp,j}$ \n",
    "    - Has non-feature dimension $(f_\\llp \\times f_\\llp)$\n",
    "    - And \"depth\" $n_{(\\ll-1)}$ (to match the number of input feature maps/channels)\n",
    "- There are $n_\\llp$ kernels in layer $\\ll$\n",
    "\n",
    "So the size of $W_\\llp$ (ignoring the optional bias term per output feature map)\n",
    "$$\n",
    "|| \\W_\\llp || = n_\\llp * (n_{(\\ll-1)} * f_\\llp * f_\\llp )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The part of the product that most concerns us is ($n_\\llp * n_{(\\ll-1)}$)\n",
    "- Values for $n_\\llp, n_{(\\ll-1)}$ in $\\{ 32, 64, 256 \\} $ are not uncommon !\n",
    "- Hence $|| \\W_\\llp ||$ is often easily several thousand\n",
    "- State of the art image recognition models use *several hundred million* weights !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How many multiplications (in the dot product) are required for layer $\\ll$ ?\n",
    "- We will ignore additions (the part of the dot product that reduces pair-wise products to a scalar, and for the bias)\n",
    "- Each kernel $\\kernel_{\\llp,j}$ of dimension \n",
    "$$(f_\\llp \\times f_\\llp \\times n_{(\\ll-1)})$$\n",
    "- Applied over each location in the $(\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2})$ non-featuer dimension of the input layer $(\\ll-1)$\n",
    "- There are $n_\\llp$ kernels in layer $\\ll$\n",
    "\n",
    "So the number of multiplications \n",
    "\n",
    "$$\n",
    "n_\\llp * (\\dim_{(\\ll-1),1} * \\dim_{(\\ll-1),2}) * (n_{(\\ll-1)} * f_\\llp * f_\\llp )\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a grey-scale image of size $(\\dim_{(\\ll-1),1} * \\dim_{(\\ll-1),2}) = (1024 \\times 1024)$\n",
    "- Lower than your cell-phones camera !\n",
    "- Easily several *million* multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Expect the time to train a Neural Network with Convolutional layers to be long !\n",
    "- That's why GPU's are important in training\n",
    "- But GPU's have limited memory so space is important too\n",
    "    - Can control with batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "All of this ignores the final layer $L$\n",
    "- Often a Fully Connected layer implementing Regression or Classification\n",
    "- With $n_L$ output features\n",
    "    - e.g., For Classification over classes in  set $C$, $\\y_{(L)}$ is a One Hot Vector of length $n_L = ||C||$\n",
    "\n",
    "Suppose layer $(L-1)$ has dimension\n",
    "$$\n",
    "|| \\y_{(L-1)} || =  (\\dim_{(L-1),1} \\times \\dim_{(L-1),2}  \\times n_{(L-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before we can use it as input to the Fully Connected Layer $L$ we flatten it to a vector of length\n",
    "$$\n",
    "(\\dim_{(L-1),1} * \\dim_{(L-1),2}  * n_{(L-1)} )\n",
    "$$\n",
    "\n",
    "The number of weights (ignoring biases) and multiplications is\n",
    "$$\n",
    "|| W_L || =  n_{(L)} * (\\dim_{(L-1),1} * \\dim_{(L-1),2}  * n_{(L-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $n_{(L)} * n_{(L-1)}$ on the order of several thousand\n",
    "- $(\\dim_{(L-1),1} * \\dim_{(L-1),2})$ on the order of several million, for images\n",
    "\n",
    "This may not even be feasible !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus, controlling the size of each layer $\\y_\\llp$ is of great *practical* importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Controlling the size of the non-feature dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Padding\n",
    "\n",
    "In our examples thus far\n",
    "- When a location in a non-feature dimensions of the input\n",
    "- Is such that, when the kernel is placed there, it extends beyond the input\n",
    "- We have added \"padding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is not strictly necessary \n",
    "- But has advantage that the size of the non-feature dimension of output $\\y_\\llp$ is the same as the input $\\y_{(\\ll-1)}$\n",
    "- One can simply *not* produce an output for such locations\n",
    "- It just means the output non-feature dimension shrinks in each dimension by $f_\\llp -1$\n",
    "    - Assuming $f_\\llp$ is odd\n",
    "    - The number of locations in which the kernel extends over the border\n",
    "    - Is Half of the filter size $(f_\\llp -1)/2$ times two (for each edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stride\n",
    "\n",
    "Thus far, we have placed the kernel over *each* location in the non-feature dimensions of the input layer.\n",
    "\n",
    "This, along with padding, ensures that the non-feature dimension of the input and output layers are identical.\n",
    "\n",
    "In the diagram below\n",
    "- $N = 1$ non-feature dimensions; length $\\dim_1 = 5$\n",
    "- $n = 1$ feature\n",
    "- $f = 3$ kernel size\n",
    "- we slide the kernel over just the first two locations (for brevity)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Sliding the kernel over each location</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv1d_sliding.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider two adjacent locations in the non-feature dimension of the input layer\n",
    "- The values of the input layer that appear in each dot product overlap\n",
    "\n",
    "By placing the kernel over *every other* location of the non-feature dimension of the input layer\n",
    "- We may still be able to recognize features\n",
    "- And reduce the size of the non-feature dimension of the output layer by a factor of 2 for each dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the diagram below\n",
    "- we use stride $S = 2$\n",
    "- center the kernel over *every other* location\n",
    "- reducing the size of the output non-feature dimension $\\dim'_1 =  \\frac{\\dim_1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Sliding the kernel with stride $S = 2$</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv1d_sliding_stride_2.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general, we can choose to choose to pass over $(S-1)$ locations in the non-feature dimension of the input layer\n",
    "- $S$ is called the *stride*\n",
    "- Up until now: $S = 1$\n",
    "- But you are free to choose\n",
    "\n",
    "When the number $N$ of non-feature dimensions is greater than $1$\n",
    "- we apply the stride $S$ to each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Size of output\n",
    " \n",
    "We can combine choices of Padding and Stride to control the size of the non-feature dimension of the output layer $\\ll$:\n",
    "\n",
    "Let\n",
    "- $\\dim_{(\\ll-1),j}$ denote the number of elements in non-feature dimension $j$ of layer $(\\ll-1)$\n",
    "- $P$ denote the number of elements added as padding on each border\n",
    "- $S$ denote the stride\n",
    "- $f_\\llp$ be the size of the filter (for each non-feature dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then the number of elements in non-feature dimension $j$ of output layer $\\llp$ is\n",
    "$$\n",
    "\\dim_{\\llp,j} = \\frac{\\dim_{(\\ll-1),j} + 2P - f_\\llp}{S} + 1\n",
    "$$\n",
    "\n",
    "You can see that increasing the stride has the biggest impact on reducing the \n",
    "size of the non-feature dimension of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pooling layer\n",
    "\n",
    "There is a layer type with the specific purpose of changing the \n",
    "size of the non-feature dimension of the output.\n",
    "\n",
    "This is called a Pooling Layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Pooling Layer combines the information from adjacent locations in the \n",
    "non-feature dimension of the input layer.\n",
    "- The \"combining\" operation may be average or maximum\n",
    "- Sacrificing the exact location in the non-feature dimension\n",
    "- Often in exchange for reduced space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pooling:\n",
    "\n",
    "- Selects an $N$-dimensional region in the non-feature dimensions\n",
    "    -  where each dimension is of length $f_\\llp$\n",
    "- Centered at each location in the non-feature dimension\n",
    "    - Of a **single feature map $j$** of the input layer $(\\ll-1)$:  $\\y_{(\\ll-1), \\ldots, j}$\n",
    "\n",
    "and produces a value in the corresponding  location of output layer $\\ll$\n",
    "- That *summarizes* the selected region by applying \n",
    "    - *pooling operation* $p_\\llp$ to the selected region\n",
    "    - typical pooling operations: maximum, average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an illustration of Pooling\n",
    "- $N = 2$ non-feature dimensions; $\\dim_1 = \\dim_2 = 4$\n",
    "- $n = 2$ features\n",
    "- $f_\\llp = 2$\n",
    "- with **stride** $S = 2$\n",
    "\n",
    "<div>\n",
    "    <br>\n",
    "    <center><strong>Conv 2D: Pooling (Max/Average)<strong></center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S32_PoolingLayer.png width=\"60%\">/<br>\n",
    "    <!-- edX: Original: <img src=\"images/PoolingLayer.jpg\"> replace by EdX created image -->\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A Pooling Layer is similar in *some* respects  to a Convolution.\n",
    "\n",
    "Recall that the One Dimensional Convolutional Layer (Conv1d) with a single input feature\n",
    "computes the following for output feature/channel $j$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\y_{\\llp,j} = \n",
    "\\begin{pmatrix}\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, 1) \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, 2) \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "\\vdots \\\\\n",
    "a_\\llp \\left( \\; N(\\y_{(\\ll-1)}, \\W_{\\llp,j}, n_{(\\ll-1)} \\cdot \\W_\\llp \\; \\right) \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The analogous One Dimensional Pooling Layer (Pooling1D) computes\n",
    "$$\n",
    "\\y_{\\llp,j} = \n",
    "\\begin{pmatrix}\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, 1) \\; \\right) \\\\\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, 2) \\; \\right) \\\\\n",
    "\\vdots \\\\\n",
    "p_\\llp \\left( \\; N'(\\y_{(\\ll-1)}, f_\\llp, n_{(\\ll-1)} \\right) \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "where\n",
    "$N'( \\; \\y_{(\\ll-1)}, f_\\llp, j \\; )$\n",
    "- selects a subsequence of $\\y_{(\\ll-1)}$ centered at $\\y_{(\\ll-1), \\ldots, j}$\n",
    "- of length $f_\\llp$\n",
    "\n",
    "and\n",
    "$p_\\llp$ is a *pooling operation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "That is, similar to a Convolutional Layer, the Pooling Layer\n",
    "- Selects a region of length $f_\\llp$\n",
    "- Centered at each location in the non-feature dimension of the input layer $(\\ll-1)$\n",
    "\n",
    "and produces a value in the corresponding  location of output layer $\\ll$\n",
    "- That *summarizes* the selected region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Observe that\n",
    "- There are *no* weights\n",
    "- No dot product\n",
    "- Just a pooling operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similar to Convolution, we can extend pooling to higher non-feature dimension ($N > 1$) and higher\n",
    "number of input channels $n_{(\\ll-1)} > 1$.\n",
    "\n",
    "Suppose the input $\\y_{(\\ll-1)}$ is $(N+1)$ dimensional of shape \n",
    "$$\n",
    "|| \\y_{(\\ll-1)} || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_{(\\ll-1)} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pooling with a stride $S > 1$\n",
    "- \"Down samples\" the non-feature dimension\n",
    "- Sacrificing some information about locality\n",
    "\n",
    "It effectively asks the question\n",
    "- Does the feature exist in a broader neighborhood of the non-feature dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The key difference between Pooling and Convolution (other than the absence of the dot product and kernel weights)\n",
    "- The pooling operation is applied to each input feature map *separately*\n",
    "- Versus *all the input feature maps* at a given location in the non-feature dimension of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pooling operations\n",
    "- Max pooling\n",
    "    - Maximum over the selected region\n",
    "    - Good for answering the question: \"Does the feature exist\" in the neighborhood\n",
    "- Average pooling\n",
    "    - average over the selected region\n",
    "    - \"blurs\" the location in the non-feature dimension when it is unimportant or highly variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Global Pooling  \n",
    "\n",
    "*Each* feature map $j$ of the input layer ($\\y_{(\\ll-1),\\ldots,j}$)\n",
    "- Is summarized by a single value produced by Max Pooling operation $p'_\\llp$\n",
    "- *eliminating* the non-feature dimensions\n",
    "- preserving the number of features\n",
    "\n",
    "$$\n",
    "\\y_{\\llp,j} = p'_\\llp( \\y_{(\\ll-1), \\ldots, j} )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <br>\n",
    "    <center><strong>Conv 2D: Global Pooling (Max/Average)</strong> </center>\n",
    "    <br>\n",
    "<img src=images/W9_L3_S36_GlobalPoolingLayer.png width=\"60%\">\n",
    "    <!-- edX: Original: <img src=\"images/GlobalPoolingLayer.png\"> replace by EdX created image -->\n",
    "    <br>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Notice that each input feature map has been reduced to a single value in the output.\n",
    "- No non-feature dimension in $\\y_\\llp$ (hence no \"$\\ldots$\")\n",
    "\n",
    "The Global Pooling operation effectively asks the question\n",
    "- Does the feature occur *anywhere* in the feature map ?\n",
    "- Losing information about the exact location in the non-feature dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Global pooling operations\n",
    "\n",
    "- Global average pooling\n",
    "    - Maximum over the feature map\n",
    "- K-Max pooling\n",
    "    - replace one dimension of the volume with the $K$ largest elements of the dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review \n",
    "\n",
    "Let's summarize our knowledge of controlling the size of $\\y_{(\\ll-1)}$:\n",
    "- Controlling the size of non-feature dimensions\n",
    "    - Increase stride\n",
    "    - Pooling\n",
    "        - Global average pooling often used in final Convolutional Layer\n",
    "- Control number of feature maps per layer\n",
    "    - Choice of $n_{\\llp,1}$\n",
    "    - Kernel size $f_\\llp = 1$\n",
    "        - preserve non-feature dimension\n",
    "        - change number of feature maps from $n_{(\\ll-1),1}$ to $n_{\\llp,1}$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Striding and Pooling\n",
    "- increase receptive field\n",
    "- typically small values (e.g., $S=2$) \n",
    "    - limited reduction\n",
    "\n",
    "Kernel size $f_\\llp = 1$\n",
    "- reduction depends on the ratio of $n_{\\llp,1}$ to $n_{(\\ll-1),1}$\n",
    "    - unlimited reduction possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kernel size 1\n",
    "\n",
    "A less obvious way to control the size of $\\y_\\llp$ is to use a kernel with $f_\\llp = 1$\n",
    "\n",
    "Why might that be ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall that a Convolutional Layer\n",
    "- Preserves the non-feature dimension\n",
    "- Replaces the channel/feature dimension (number of feature maps)\n",
    "\n",
    "\n",
    "That is\\\n",
    "$$\n",
    "\\begin{array}\\\\\n",
    "|| \\y_{(\\ll-1)} || & = & (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N }, & \\mathbf{n_{(\\ll-1)}} ) \\\\\n",
    "|| \\y_\\llp || &  = & (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N},  &\\mathbf{n_\\llp} )\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So a kernel of size $f_\\llp =1$ in all $N$ non-feature dimensions\n",
    "- With \"depth\" $n_{(\\ll-1)}$\n",
    "- Is just a way to resize $\\y_{(\\ll-1)}$ from $n_{(\\ll-1)}$ feature maps to a *single* feature map\n",
    "    - That sums, across feature maps, the elements in each feature map at the same location\n",
    "\n",
    "In other words:\n",
    "- Yet another way to reduce the size of $\\y_\\llp$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Receptive field\n",
    "\n",
    "The filter size $f_\\llp$ also plays a role in the space and time requirements of a Convolutional Layer.\n",
    "\n",
    "It turns out that\n",
    "- We can achieve the effect of a large $f_\\llp$\n",
    "- With a smaller $f_\\llp$ in conjunction with *more* Convolutional Layers\n",
    "\n",
    "Let's demonstrate this by examining the concept of [Receptive field](CNN_Receptive_Field.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CNN advantages/disadvantages\n",
    "\n",
    "**Advantages**\n",
    "- Translational invariance\n",
    "    - feature can be anywhere\n",
    "- Locality\n",
    "    - feature depends on nearby features, not the entire set of features\n",
    "    - reduced number of parameters compared to a Fully Connected layer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Disadvantages**\n",
    "- Output feature map is roughly same size as input\n",
    "    - lots of computation to compute a single output feature\n",
    "        - one per feature of input map\n",
    "    - higher computation cost\n",
    "        - training and inference\n",
    "- Translational invariance not always a positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How many feature maps to use (What value to choose for $n_\\llp$)\n",
    "[Bag of Tricks for Image Classification with CNNs](https://arxiv.org/abs/1812.01187)\n",
    "\n",
    "\n",
    "Remember that a larger value for $n_\\llp$ will increase space and time requirements.\n",
    "\n",
    "One rule of thumb:\n",
    "- For $N=2$\n",
    "- With filter size $f_\\llp$\n",
    "- The number of elements in the non-feature dimension of input $\\y_{(\\ll-1)}$ involved in the dot product is\n",
    "$$e = (n_{(\\ll-1)} * f_\\llp * f_\\llp )$$\n",
    "- It may not make sense to create *more* than $e$ output features $n_\\llp > e$\n",
    "    - We would generate more features than input elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inverting convolution\n",
    "\n",
    "The typical flow for multiple layers of Convolutions\n",
    "- Is for the non-feature dimension of successive layers to get smaller\n",
    "- By using stride $S > 1$\n",
    "- By using Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This brings up the question: Can we invert the process ?\n",
    "- That is, go from a smaller non-featue dimension back to the non-feature dimension of input layer $0$\n",
    "\n",
    "The answer is yes.\n",
    "\n",
    "This process is sometimes called *Deconvolution* or *Transposed Convolution*.\n",
    "- In a Deeper Dive, we relate Convolution to Matrix Multiplication\n",
    "- So the inverting matrix's *dimensions* are the transpose of the matrix implementing the convolution\n",
    "\n",
    "We will revisit this in the lecture addressing \"What is a CNN looking for ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Technical points\n",
    "\n",
    "## Convolution versus Cross Correlation\n",
    "- math definition of convolution\n",
    "    - dot product of input and *reversed* filter\n",
    "    - we are doing [cross correlation](https://en.wikipedia.org/wiki/Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
