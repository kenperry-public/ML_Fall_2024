{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( #1 \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pre-train, prompt, predict \n",
    "\n",
    "If you expect a \"raw\" LLM (e.g., GPT-3) to behave like ChatGPT: you will be disappointed.\n",
    "- the LLM is trained to \"predict the next\" token\n",
    "    - continue the text given in the prompt\n",
    "- ChatGPT  is a raw LLM that has been Fine-Tuned to be\n",
    "    - A Helpful Assistant: answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There *are* ways to adapt the raw LLM to be more like ChatGPT without Fine-Tuning.\n",
    "\n",
    "Respect the LLM training objective.  \n",
    "- Turn your questions into instances of \"text continuation\"\n",
    "    - the Universal API\n",
    "- Use In-Context Learning: exemplars that illustrate the behavior of a Helpful Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here are suggestions on how to get the \"expected behavior\" out of the LLaMa LLM:\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <center><strong>Prompts to get a raw LLM to generate helpful results</strong></center>\n",
    "    <img src=\"images/Llama_guide_to_good_generating.png\">\n",
    "    <br>\n",
    "    Attribution: https://github.com/facebookresearch/llama/blob/llama_v1/FAQ.md\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This new paradigm of adapting the behavior of a Pre-Trained model *without* further Fine-Tuning\n",
    "is called [\"Pre-train, Prompt, Predict\"](https://arxiv.org/pdf/2107.13586.pdf).\n",
    "\n",
    "In this module, we explore the \"art\" of constructing prompts to elicit new behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prompt engineering\n",
    "\n",
    "You see how the behavior of the LLM can be affected by the exact form of the prompt.\n",
    "- the number of exemplars\n",
    "\n",
    "It is also the case that slightly changing the words (and order of words) affects behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is a whole literature on creating successful prompts:\n",
    "- this [website](https://www.promptingguide.ai/) gives good advice in crafting a prompt to meet your expectations\n",
    "- this [paper](https://arxiv.org/pdf/2107.13586.pdf) is a systematic survey\n",
    "- OpenAI provides [helpful examples](https://platform.openai.com/examples) for prompting.\n",
    "- [See Appendix G](https://arxiv.org/pdf/2005.14165.pdf#page=51) (pages 50+) for examples of prompts on creating prompts to solve some standard tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We won't examine all of the useful tricks.\n",
    "\n",
    "But one method has proven to be exceptionally successful: Chain of Thought Prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chain of thought prompting\n",
    "\n",
    "[Paper: Chain of thought prompting](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "\n",
    "In school, students are often tasked with solving problems involving multiple steps.\n",
    "\n",
    "LLM's are better at multi-step reasoning tasks when they have been conditioned to answer step by step.\n",
    "\n",
    "We call this *chain of thought (CoT)* prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **exemplars** used in CoT prompting\n",
    "- demonstrate step by step reasoning in the expected output\n",
    "\n",
    "We can see the difference in the exemplar's \"Example Output\" section\n",
    "- using \"Standard Prompting\" (on the left)\n",
    "- versus using \"CoT Prompting\" (on the right)\n",
    "    - the first exemplar (example) demonstrates step-by-step reasoning\n",
    "\n",
    "<table>\n",
    "    <center><strong>Chain of Thought Prompting</strong></center>\n",
    "    <tr>\n",
    "        <img src=\"images/cot_prompt_example.png\" width=80%>\n",
    "    </tr>\n",
    "    \n",
    "    Attribution: https://arxiv.org/pdf/2201.11903.pdf\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How does this apply to the case of *zero* exemplars (zero-shot learning) ?\n",
    "\n",
    "It turns out that step by step reasoning can be elicited\n",
    "- Just by adding the phrase [\"Let's think step by step\"](https://arxiv.org/pdf/2205.11916.pdf) to the end of the query\n",
    "\n",
    "Let's see an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's ask ChatGPT to solve a multi-step reasoning problem in a zero-shot setting.\n",
    "\n",
    "As you can see: it comes close, by produces an incorrect answer.\n",
    "\n",
    "<img src=\"images/cot_prompt_no_step_by_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The reasoning logic is correct, but the math is wrong.\n",
    "\n",
    "Now, let's run the same query but append a request to answer step-by-step.\n",
    "\n",
    "<img src=\"images/cot_prompt_step_by_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The \"LETS THINK STEP BY STEP\" seems to condition the model into getting the math correct\n",
    "- Without CoT: answers comes before reasoning\n",
    "- With CoT: reasoning precedes answer\n",
    "\n",
    "It is the conditioning of providing the reasoning before the answer that seems to improve the behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using zero-shot to create new applications\n",
    "\n",
    "With a little cleverness, one can almost trivially create a new application using a LLM in zero-shot mode\n",
    "- create the prefix of a prompt describing the task\n",
    "- append the user input to the prefix to complete the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we use [`ChatGPT`](https://chat.openai.com/chat) to create an app that summarizes a conversation\n",
    "- we create a prompt with a \"place-holder\" (in braces `{..}`) for user input\n",
    "\n",
    "`prompt = Summarize the following conversation: {user input}`\n",
    "\n",
    "<img src=\"images/chatgpt_summarize_conversation_example.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here we use ChatGPT as a programming assistant\n",
    "\n",
    "`prompt = Write a Python function that does the following: {task description}`\n",
    "\n",
    "<img src=\"images/chatgpt_program_generation_example.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some more, creative examples\n",
    "- [Spreadsheet add-in to perform lookups](https://twitter.com/pavtalk/status/1285410751092416513)\n",
    "- [Generate a web page from a description](https://twitter.com/sharifshameem/status/1283322990625607681)\n",
    "\n",
    "References found in: http://ai.stanford.edu/blog/understanding-incontext/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How is zero-shot learning possible ? Some theories\n",
    "\n",
    "**Theory 1**\n",
    "\n",
    "- The training set contains explicit instances of these out of sample tasks\n",
    "\n",
    "**Theory 2**\n",
    "\n",
    "- The super-large training sets  contain *implicit* instances of these out of sample tasks\n",
    "    - For example: an English-language article quoting a French speaker in French with English translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One thing that jumps out from the graph:\n",
    "- Bigger models are more likely to exhibit meta-learning\n",
    "\n",
    "**Theory 3**\n",
    "\n",
    "The training sets are so big that the model \"learns\" to create groups of examples with a common theme\n",
    "- Even with the large number of parameters, the model capacity does not suffice for example memorization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Another thing to consider\n",
    "- The behavior of an RNN depends on *all* previous inputs\n",
    "    - It has memory (latent state, etc.)\n",
    "    \n",
    "So Few Shot Learning may work by \"priming\" the memory with parameters for a specific task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Social concerns\n",
    "\n",
    "The team behind GPT is very concerned about potential misuse of Language Models.\n",
    "\n",
    "To illustrate, they conducted an experiment in having a Language Model construct news articles\n",
    "- Select title/subtitle of a genuine news article\n",
    "- Have the Language Model complete the article from the title/subtitle\n",
    "- Show humans the genuine and generated articles and ask them to judge whether the article was written by a human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Human accuracy in detecting model generated news articles</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/LM_GPT_model_generated_news.png\" width=80%></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><center>Picture from: https://arxiv.org/pdf/2005.14165.pdf</center></td>\n",
    "    </tr>   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The bars show the range of accuracy across the 80 human judges.\n",
    "\n",
    "- 86% accuracy detecting articles created by a really bad model (the control)\n",
    "- 50% accuracy detecting articles created by the biggest models\n",
    "\n",
    "It seems that humans might have difficulty distinguishing between genuine and generated articles.\n",
    "\n",
    "The fear is that Language Models can be used\n",
    "- to mislead\n",
    "- to create offensive speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Harmful behavior of the Pre-Trained LLM\n",
    "\n",
    "Another important concern is that LLM's can exhibit bias\n",
    "- we saw similar behavior with embeddings\n",
    "- the bias is statistical: a property of the training data\n",
    "\n",
    "Any model based on the Pre-Trained model might inherit this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A recent trend in model development\n",
    "- is to probe the model for harmful behavior\n",
    "\n",
    "Models are now often described via a [Model card](https://arxiv.org/abs/1810.03993)\n",
    "- describing both the technical properties\n",
    "- and the social aspects (biases)\n",
    "\n",
    "[Here](https://huggingface.co/openai-gpt) is an example of a model card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
