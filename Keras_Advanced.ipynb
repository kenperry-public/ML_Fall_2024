{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\E}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Keras: motivation\n",
    "\n",
    "We have been using the Keras Model API (mostly the `Sequential`) as a black box.\n",
    "\n",
    "But it is highly customizable\n",
    "- A `Model` is a class (as in Python object)\n",
    "- It implements methods such as\n",
    "    - `compile`\n",
    "    - `fit`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can change the behavior of a model in several ways\n",
    "- Arguments to some methods are objects; we can pass non-default functions/objects\n",
    "    - e.g., custom loss function\n",
    "- We can override these (and other) methods to make our models do new things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `Layer` is also an abstract class (Python) in Keras.\n",
    "\n",
    "Hence\n",
    "- We can create new layer types\n",
    "- We can override the methods of a given layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this module\n",
    "- we will\n",
    "illustrate techniques that you can use to customize your Layers/Models.\n",
    "- Illustrate the Functional model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model specialization\n",
    "\n",
    "## Custom loss (passing in a loss function)\n",
    "\n",
    "In introducing Deep Learning, we have asserted that\n",
    ">It's all about the Loss function\n",
    "\n",
    "That is: the key to solving many Deep Learning problems\n",
    "- Is not in devising a complex network architecture\n",
    "- But in writing a Loss function that captures the semantics of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Up until now\n",
    "- We have been  using pre-defined Loss functions (e.g., `binary_crossentropy`)\n",
    "- Specifying the Loss function in the compile statement\n",
    ">`model.compile(loss='binary_crossentropy')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You can [write your own loss functions](https://keras.io/api/losses/)\n",
    "\n",
    "In Keras, a Loss function has the signature\n",
    ">`loss_fn(y_true, y_pred, sample_weight=None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Custom train step (override `train_step`)\n",
    "\n",
    "But what if your Loss function needs access to values that are not part of the signature ?\n",
    "\n",
    "Or what if you want to change the training loop ?\n",
    "\n",
    "You could write your own training loop by overriding the `fit` method\n",
    "- Cycle through epochs\n",
    "- Within each epoch, cycle through mini-batches of examples\n",
    "- For each mini-batch of examples: execute the *train step*\n",
    "    - forward pass: feed input examples to Input layer, obtain output\n",
    "    - compute the loss\n",
    "    - Compute the gradient of the loss with respect to the weights\n",
    "    - Update the weights\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "initialize(W)\n",
    "\n",
    "# Training loop to implement mini-batch SGD\n",
    "for epoch in range(n_epochs):`\n",
    "    for X_batch, y_batch in next_batch(X_train, y_train, batch_size, shuffle=True):\n",
    "        # Forward pass\n",
    "        y = NN(X_batch)\n",
    "        \n",
    "        # Loss calculation\n",
    "        loss = loss_fn(y, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        grads = gradient(loss, W)\n",
    "        \n",
    "        # Update \n",
    "        W = W - grads * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rather than overriding `fit`, it sometimes suffices to override the train step: `train_step`\n",
    "\n",
    "Let's start by looking at the \"standard\" implementation of a basic train step.\n",
    "\n",
    "We will see\n",
    "- How losses are computed\n",
    "- Gradients are obtained\n",
    "- Weights are updated\n",
    "\n",
    "[Basic `train_step`](https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/customizing_what_happens_in_fit.ipynb#scrollTo=9022333acaa7&line=1&uniqifier=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can modify the basic training step too.\n",
    "\n",
    "For example: suppose we want to make some training examples \"more important\" than others\n",
    "- Rather than Total Loss as equally-weighted average over all examples\n",
    "- Pass in per-example weights\n",
    "\n",
    "This might be useful, for example, when dealing with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Layer` specialization\n",
    "\n",
    "A `Layer` in Keras is an abstract (Python) object\n",
    "- instantiating the object returns a function\n",
    "    - That maps input to the layer to the output\n",
    "\n",
    "We have used specific instances of `Layer` objects (e.g., `Dense`) as arguments in the list passed to the `Sequential` model type.\n",
    "\n",
    "We can also use instances in the Functional Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example\n",
    "- `Dense(10)`\n",
    "    - Is the constructor for a fully connected layer instance with 10 units\n",
    "    - The constructor returns a function\n",
    "    - The the function maps the layer inputs to the outputs of the computation defined by the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So you will see code fragments like\n",
    ">\n",
    "    x = Input(shape=(784))\n",
    "    x = Dense(10, activation=softmax)(x)\n",
    "    \n",
    "- Re-using the variable `x` as the output of the current layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When the function is invoked, the Layer's `call` method is used\n",
    "- `call` gets invoked implicitly by \"parenthesized argument\" juxtaposition\n",
    "    - e.g., `Dense(10) ( x )`\n",
    "    - is similar to `obj= `Dense(10); result = obj.call(x)`\n",
    "- The function maps the inputs to the layer to the output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Overriding `call` allows us to defined a new `Layer` sub-class.\n",
    "\n",
    "For example, [here](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=AupqfNAYaCHn&line=2&uniqifier=1) is the code defining some new `Layer` types that will be used to create a `Transformer` layer type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The output of `Dense(10)` is a Tensor with final dimension equal to the number of units (e.g., 10)\n",
    "- The Tensor has leading dimensions too\n",
    "    - e.g., the implicit \"batch index\" dimension\n",
    "    - since the layer takes a mini-batch of examples (rather than a single example) as input\n",
    "- It may have *additional* dimensions too !\n",
    "    - Just like `numpy`: threading over additional dimensions\n",
    "    - e.g., if input is shape $(\\text{minibatch_size} \\times n_1 \\times n_2)$\n",
    "        - output is shape $(\\text{minibatch_size} \\times n_1 \\times 10)$\n",
    "        - `Dense` operates over the final dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Studying advanced models\n",
    "\n",
    "The best way to learn is to study the code of some non-trivial models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformer: Custom layers, Skip connections, Layer Norm\n",
    "\n",
    "We have already seen part of the Transformer in introducing the basics of the Functional model.\n",
    "\n",
    "We use the rest of this example to discover other advanced Keras techniques:\n",
    "\n",
    "[Transformer layer](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=4DaEQr-lMkSs)\n",
    "- [Custom layers](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb#scrollTo=Ywxggf9Anabk&line=8&uniqifier=1)\n",
    "- Layer Norm\n",
    "- Skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Custom layers: subtle point\n",
    "\n",
    "Let's look at the constructor for the `TransformerEncoder` custom layer, as an example\n",
    "\n",
    "    class TransformerEncoder(layers.Layer):\n",
    "        def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "            super(TransformerEncoder, self).__init__(**kwargs)\n",
    "            self.embed_dim = embed_dim\n",
    "            self.dense_dim = dense_dim\n",
    "            self.num_heads = num_heads\n",
    "            self.attention = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=embed_dim\n",
    "            )\n",
    "            self.dense_proj = keras.Sequential(\n",
    "                [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "            )\n",
    "            self.layernorm_1 = layers.LayerNormalization()\n",
    "            self.layernorm_2 = layers.LayerNormalization()\n",
    "            self.supports_masking = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The custom layer consists of a collection of component layers\n",
    "\n",
    "Why are the components layers (e.g., Dense, MultiHeadAttention, LayerNormalization) instantiated in the class constructor\n",
    "- As opposed to being defined in the `call` method \n",
    "\n",
    "Had we instantiated each component within the `call` method\n",
    "- There would be a *new instance* of each component *each time the layer was called on an example* in training !\n",
    "- Each instance would have *it's own weights*\n",
    "- So training would not \"learn\" between examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other custom layers of interest\n",
    "\n",
    "We can dig deeper to examine how the Attention layers are implemented in code:\n",
    "- [Scaled dot-product attention](https://www.tensorflow.org/text/tutorials/transformer#scaled_dot_product_attention)\n",
    "- [Multi-head attention](https://www.tensorflow.org/text/tutorials/transformer#multi-head_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## VAE: Custom Model -- Custom Layer, Training Loop, the Gradient Tape\n",
    "\n",
    "We use this example to show\n",
    "- The Functional model\n",
    "- A custom `Layer`: `Sampling`\n",
    "- A custom training step\n",
    "- Inverting a Convolution: `Conv2DTranspose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall the architecture of a Variational Autoencoder (VAE)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Variational Autoencoder (VAE)</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_VAE.png\"></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A key step is drawing a random latent vector $\\z^\\ip$\n",
    "from a distribution with mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\n",
    "This [cell](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=Wx_jzzcPtcfz)\n",
    "- Creates a custom `Layer` type called `Sampling` to perform the random sampling\n",
    "- By overriding the base `Layer` `call` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In [this cell](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=4rFiHtbCtcf0) we can see that the Encoder and Decoder are both implemented as Functional models\n",
    "- The Encoder produces a *pair of outputs*: $(\\mu, \\sigma)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Issues**\n",
    "- Custom **model** (not layer) class VAE\n",
    "- The *reconstruction loss* depends on the output of the Decoder part of the VAE\n",
    "    - No other obvious way to define this loss aside from a **custom training** step\n",
    "- Because we are computing the Loss in the training step\n",
    "    - we must compute the gradient of the Loss w.r.t weights\n",
    "    - Update the weights (**gradient tape**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Variational Autoencoder (VAE) from github](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=DEU05Oe0vJrY)\n",
    "- [VAE: Custom train step](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/vae.ipynb#scrollTo=0EHkZ1WCHw9E)\n",
    "    - Complex loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing what CNN's learn: Gradient Ascent and the Gradient Tape\n",
    "\n",
    "[Visualizing what Convnets learn](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/visualizing_what_convnets_learn.ipynb#scrollTo=K8ITQAj7FTZd)\n",
    "- The Gradient Tape\n",
    "- Maximize utility (negative loss)\n",
    "    - mean (across the spatial dimensions) of one feature map in a multi-layer CNN\n",
    "    - the \"weights\" being solved for are the pixels of the input image !\n",
    "\n",
    "We use this example to show how powerful the Gradient Tape is\n",
    "\n",
    "[Gradient ascent](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/visualizing_what_convnets_learn.ipynb#scrollTo=a9hZnslRFTZZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Factor Models and Autoencoders: Threading\n",
    "\n",
    "We use this example to show\n",
    "- A Functional model applied to a common problem in Finance.\n",
    "- Threading\n",
    "\n",
    "We will cover the Finance aspects of this in a [separate module](Autoencoder_for_conditional_risk_factors.ipynb)\n",
    "\n",
    "For now, I want to focus on the idea and the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is the code, excerpted from the [notebook](https://github.com/stefan-jansen/machine-learning-for-trading/blob/main/20_autoencoders_for_conditional_risk_factors/06_conditional_autoencoder_for_asset_pricing_model.ipynb)\n",
    "\n",
    "    def make_model(hidden_units=8, n_factors=3):\n",
    "        input_beta = Input((n_tickers, n_characteristics), name='input_beta')\n",
    "        input_factor = Input((n_tickers,), name='input_factor')\n",
    "\n",
    "        hidden_layer = Dense(units=hidden_units, activation='relu', name='hidden_layer')(input_beta)\n",
    "        batch_norm = BatchNormalization(name='batch_norm')(hidden_layer)\n",
    "\n",
    "        output_beta = Dense(units=n_factors, name='output_beta')(batch_norm)\n",
    "\n",
    "        output_factor = Dense(units=n_factors, name='output_factor')(input_factor)\n",
    "\n",
    "        output = Dot(axes=(2,1), name='output_layer')([output_beta, output_factor])\n",
    "\n",
    "        model = Model(inputs=[input_beta, input_factor], outputs=output)\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Not obvious what is going on here.\n",
    "\n",
    "A picture will help:\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Autoencoder for Conditional Risk Factors</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Autoencoder_for_conditional_risk_factors.png\" width=\"90%\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\R}{\\mathbf{R}}\n",
    "\\newcommand{\\r}{\\mathbf{r}}\n",
    "\\newcommand{\\F}{\\mathbf{F}}\n",
    "\\newcommand{\\V}{\\mathbf{V}}\n",
    "\\newcommand{\\ntickers}{{n_\\text{tickers}}}\n",
    "\\newcommand{\\ndates}{{n_\\text{dates}}}\n",
    "\\newcommand{\\nfactors}{{n_\\text{factors}}}\n",
    "\\newcommand{\\nchars}{{n_\\text{chars}}}\n",
    "\\newcommand{\\dp}{{(d)}}\n",
    "\\newcommand{\\sp}{{(s)}}\n",
    "\\newcommand{\\Bbeta}{\\mathbf\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Threading \n",
    "\n",
    "Let's focus on the `Dense` layer corresponding to the box labelled \"Beta\" in the picture\n",
    "\n",
    "- `Dense` $( \\nfactors )$\n",
    "\n",
    "From the diagram you will notice that \n",
    "- the input to this  layer is *two dimensional*: $(\\ntickers \\times \\nchars)$\n",
    "- the output to this is *two dimensional*: $(\\ntickers \\times \\nfactors)$\n",
    "\n",
    "We have not yet seen multi-dimensional input/output in regard to a `Dense` layer\n",
    "\n",
    "What is going on here ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The layer is implementing a function with signature\n",
    "- `Dense`( $\\nfactors ) :  (\\ntickers \\times \\nchars) \\mapsto (\\ntickers \\times \\nfactors) $\n",
    "\n",
    "Tensorflow/Keras works on higher dimensional objects just like NumPy: \n",
    "- [threading](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) over \"extra\" dimensions\n",
    "\n",
    "If the input to layer $\\ll$ is shape $(\\dim_{\\llp,1} \\times \\dim_{\\llp,2} \\times \\ldots \\dim_{\\llp,N} \\,\\, \\times n_\\llp )$\n",
    "- And the layer type operates over a *single* dimension (usually the last dimension)\n",
    "    - producing output shape $n_{(\\ll+1)}$    \n",
    "\n",
    "Then threading treats the inputs\n",
    "- as a tensor of shape $(\\dim_{\\llp,1} \\times \\dim_{\\llp,2} \\times \\ldots \\dim_{\\llp,N} )$ instances, each of shape $n_\\llp $\n",
    "\n",
    "Producing an output of shape \n",
    "- If the input to layer $\\ll$ is shape $(\\dim_{\\llp,1} \\times \\dim_{\\llp,2} \\times \\ldots \\dim_{\\llp,N} \\,\\, \\times n_{(\\ll+1)} )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our case\n",
    "- Input shape is $(\\ntickers \\times \\nchars)$\n",
    "- The `Dense` layer is defined with $\\nfactors$ units ($n_{(\\ll+1)} = \\nfactors$)\n",
    "- Hence, the output shape is $(\\ntickers \\times \\nfactors)$\n",
    "\n",
    "The weight matrix for this layer\n",
    "- $\\W_\\beta$ with shape $( \\nfactors \\times \\nchars )$\n",
    "    - just like any `Dense` layer; number of weights is *independent* of threading\n",
    "- applies the *same weights* to each of the $\\ntickers$ (the rows) of the input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neural Style Transfer: Feature extractor, Training Loop\n",
    "\n",
    "We use this example to illustrate\n",
    "- [Complex Loss and Training Loop](https://keras.io/examples/generative/neural_style_transfer/#compute-the-style-transfer-loss)\n",
    "- [Feature extractor](https://keras.io/examples/generative/neural_style_transfer/#compute-the-style-transfer-loss)\n",
    "\n",
    "[Here](https://www.tensorflow.org/tutorials/generative/style_transfer) is a tutorial view of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autoencoder: Functional model\n",
    "\n",
    "\n",
    "<!--- #include (Autoencoder_example.ipynb)) --->\n",
    " [Autoencoder example from github](https://colab.research.google.com/github/kenperry-public/ML_Spring_2024/blob/master/Autoencoder_example.ipynb)\n",
    "- Functional model\n",
    "\n",
    "**Issues**\n",
    "- We could use a Sequential model with initial Encoder layers and final Decoder layers\n",
    "    - But we would not be able to independently access the Encoder nor the Decoder as isolated models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GAN\n",
    "\n",
    "We use this example to show\n",
    "- A custom training step\n",
    "- Inverting a Convolution: `Conv2DTranspose`\n",
    "\n",
    "Recall: the training of a GAN is an iterative process among two \"players\"\n",
    "- the Discriminator\n",
    "- the Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Custom `train_step`\n",
    "\n",
    "Here is a summary from our introductory module on [GANs](GAN_Overview.ipynb)\n",
    "\n",
    "**Competitive training**\n",
    "\n",
    "Iteration $\\tt$\n",
    "\n",
    "- Train $D_{\\Theta_{D, (\\tt-1)}}$ on samples\n",
    "    - $\\tilde{\\x} \\in p_\\text{data} \\cup p_{\\text{model}, (\\tt-1)}$\n",
    "        - where $G_{\\Theta_{G, (\\tt-1)}} ( \\z) \\in p_{\\text{model}, (\\tt-1)}$\n",
    "    - Update $\\Theta_{D, (\\tt-1)}$ to $\\Theta_{D, \\tp}$ via gradient $\\frac{\\partial \\loss_D}{\\partial \\Theta_{D,(\\tt-1)}}$\n",
    "        - $D$ is a maximizer of $\\int_{\\x \\in p_\\text{data}} \\log D(\\x) + \\int_{\\z \\in p_\\z} \\log ( \\, 1 - D(G(\\z)) \\, )$\n",
    "- Train $G_{\\Theta_{G, (\\tt-1)}}$ on random samples $\\z$\n",
    "    - Create samples $\\hat{\\x}_\\tp \\in G_{\\Theta_{G, (\\tt-1)}}(\\z)  \\in p_\\text{model}$\n",
    "    - Have Discriminator $D_{\\Theta_{D, \\tp}}$ evaluate $D_{\\Theta_{D,\\tp}} ( \\hat{\\x}_\\tp )$\n",
    "    - Update $\\Theta_{G, (\\tt-1)}$ to $\\Theta_{G, \\tp}$ via gradient $\\frac{\\partial \\loss_G}{\\partial \\Theta_{G,(\\tt-1)}}$\n",
    "        - $G$ is a minimizer of $\\int_{\\z \\in p_\\z} \\log ( \\, 1 - D(G(\\z)) \\, )$\n",
    "            - i.e., want $D(G(\\z))$ to be high\n",
    "    - May update $G$ multiple times per update of $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Keras, one can override a `Model`'s `train_step` method in order to replace the\n",
    "treatment of a single mini-batch of examples.\n",
    "\n",
    "Let's see how this is applied to a [simple GAN](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=OzzFLmKIpv0j)\n",
    "\n",
    "Key points to observe;\n",
    "- Discriminator trained first\n",
    "    - Create examples from real and fake images, to be fed to Discriminator\n",
    "    \n",
    "          # Decode them to fake images\n",
    "          generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "          # Combine them with real images\n",
    "          combined_images = tf.concat([generated_images, real_images], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Train the Discriminator on the combined real/fake images and update it's weights\n",
    "\n",
    "            # Train the discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = self.discriminator(combined_images)\n",
    "                d_loss = self.loss_fn(labels, predictions)\n",
    "            grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(grads, self.discriminator.trainable_weights)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Train the Generator\n",
    "    - Have it create fake images from random, latent vectors\n",
    "    - Let the Discriminator evaluate these fakes\n",
    "    - Update Generator weights to better be able to fool Discriminator\n",
    "    \n",
    "    \n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `Conv2DTranspose`: Inverting a Convolution\n",
    "\n",
    "A CNN layer\n",
    "- creates new features, for each element of the spatial dimension of the layer input\n",
    "- May \"down-sample\" the input (reduce spatial dimension)\n",
    "    - Using a stride greater than 1\n",
    "    \n",
    "We can invert the Convolution, and \"up-sample\" (increase the spatial dimension)\n",
    "- with the `Conv2DTranspose` layer type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- We can see the Discriminator using Convolutional layers with down-sampling\n",
    "- And the Generator using transposed Convolutional layers with up-sampling\n",
    "\n",
    "in this [cell](https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/generative/ipynb/dcgan_overriding_train_step.ipynb#scrollTo=OrfSmOevpv0h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Simple GAN](https://keras.io/examples/generative/dcgan_overriding_train_step)\n",
    "- [Custom train step: GAN training](https://keras.io/examples/generative/dcgan_overriding_train_step/#override-trainstep)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wasserstein GAN with Gradient Penalty\n",
    "[Wasserstein GAN with Gradient Penalty](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Gradient Tape: used for loss term, rather than weight update](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Overide `compile`](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)\n",
    "- [Custom train step: GAN training](https://keras.io/examples/generative/wgan_gp/#create-the-wgangp-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "369.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
