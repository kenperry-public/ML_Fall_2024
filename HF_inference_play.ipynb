{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw4nryteX38f",
        "outputId": "41275d8f-d32c-4532-b1a6-c7ac37b86321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're running Colab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypuy3uSgX5Hm",
        "outputId": "d1ecc66b-3327-43d5-c33d-59608948eec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running TensorFlow version  2.15.0\n",
            "Version 2, minor 15\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Running TensorFlow version \",tf.__version__)\n",
        "\n",
        "# Parse tensorflow version\n",
        "import re\n",
        "\n",
        "version_match = re.match(\"([0-9]+)\\.([0-9]+)\", tf.__version__)\n",
        "tf_major, tf_minor = int(version_match.group(1)) , int(version_match.group(2))\n",
        "print(\"Version {v:d}, minor {m:d}\".format(v=tf_major, m=tf_minor) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPIH-NNX8y4",
        "outputId": "f3c03303-dd67-42c7-fec2-cf99e00ed315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print('Using GPU')\n",
        "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
        "else:\n",
        "    print('Using CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YS8mj2c5bKKk",
        "outputId": "1e04fc56-8783-4c7b-e057-c8ace5461a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.27.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.15.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  !pip install datasets evaluate transformers[sentencepiece]\n",
        "  !pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oftFp7iFbJRe"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29bnSo8t9EmN"
      },
      "source": [
        "# Use an Inference end-point\n",
        "- Advange:\n",
        "  - free\n",
        "  - does not use *local* RAM so can run big models\n",
        "- [paid hosting](https://huggingface.co/pricing#endpoints)\n",
        "  - don't get charged for a *paused* end-point\n",
        "- [guide](https://huggingface.co/docs/inference-endpoints/index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TTlN7j78659Q"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "def get_API_token(token_file=\"/content/hf.token\"):\n",
        "    # Check for file containing API token to HuggingFace\n",
        "    p = Path(token_file).expanduser()\n",
        "    if not p.exists():\n",
        "      print(f\"Token file {p} not found.\")\n",
        "      return\n",
        "\n",
        "    with open(token_file, 'r') as fp:\n",
        "        token = fp.read()\n",
        "\n",
        "    # Remove trailing newline\n",
        "    token = token.rstrip()\n",
        "\n",
        "    return token\n",
        "\n",
        "API_TOKEN=get_API_token();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XtKwuir07YDZ"
      },
      "outputs": [],
      "source": [
        "gen_text_key = \"generated_text\"\n",
        "input_key = \"inputs\"\n",
        "error_key = \"error\"\n",
        "\n",
        "models = { \"small\": \"EleutherAI/gpt-neo-1.3B\",\n",
        "           \"big\":   \"EleutherAI/gpt-neox-20b\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQERqi6o659R",
        "outputId": "18807f51-f36f-44ed-8192-650435eaa33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.22 seconds, using EleutherAI/gpt-neox-20b]\n",
            " this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things about this one: negative \n",
            " it is entertaining: positive \n",
            " I would not see this one again: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things: negative \n",
            " it is entertaining: positive \n",
            " I've heard not so great things: negative \n",
            " enchanced by slow motion visuals: positive \n",
            " excellent: positive \n",
            " terrific sound design in this one too: positive \n",
            " Stallone is a great actor: positive \n",
            " I'd turn down a free trip to London to see this movie:\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "\n",
        "def query(payload, model_string):\n",
        "  API_URL = f\"https://api-inference.huggingface.co/models/{model_string}\"\n",
        "\n",
        "  response = requests.post(API_URL, headers=headers, json=payload)\n",
        "  return response.json()\n",
        "\n",
        "def execute_query(q, model_string):\n",
        "  output = query({  input_key: q }, model_string)\n",
        "\n",
        "  # Successful output is a list; error output is a dict\n",
        "  if type(output) is dict:\n",
        "    out = f\"Error: {output[error_key]}\"\n",
        "  else:\n",
        "    out = output[0][gen_text_key]\n",
        "\n",
        "  return out\n",
        "\n",
        "\n",
        "\n",
        "exemplars = [ \"this movie was great: positive\",\n",
        "             \"one of the best films of the year: positive\",\n",
        "             \"just plain awful: negative\",\n",
        "             \"I would not see this one again: negative\",\n",
        "             \"this movie was great: positive\",\n",
        "             \"one of the best films of the year: positive\",\n",
        "             \"just plain awful: negative\",\n",
        "             \"I would not see this one again: negative\",\n",
        "             \"I love this film: positive\"\n",
        "]\n",
        "\n",
        "sep = \" \\n \"\n",
        "exemplar_string = sep.join(exemplars)\n",
        "few_shot_string =  exemplar_string + sep + \"I've heard not so great things about this one:\"\n",
        "\n",
        "q = few_shot_string\n",
        "\n",
        "# q = \"Can you please let us know more details about your \"\n",
        "\n",
        "# Can run a very large model since execution is on remote end-point\n",
        "model_string = models[\"big\"]\n",
        "\n",
        "time_start = time.time()\n",
        "\n",
        "res = execute_query(q, model_string)\n",
        "\n",
        "time_end = time.time()\n",
        "\n",
        "print(f\"[{time_end-time_start:3.2f} seconds, using {model_string}]\\n {res}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W36n_ylXJ2Of"
      },
      "source": [
        "# Use a pipeline\n",
        "- runs locally\n",
        "- so can only use model small enough to fit in RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4JuoPKewcOni"
      },
      "outputs": [],
      "source": [
        "model_string = models[\"small\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gszFoZ4u659R",
        "outputId": "d9737fbb-7c89-4fd5-a1d0-3129c6a117f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "num_return = 3\n",
        "len_return = 30\n",
        "\n",
        "\n",
        "generator = pipeline('text-generation', model = model_string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68lsHGxO8esU",
        "outputId": "9a6e7af9-61bd-467f-cdb7-fb297f460cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[76.46 seconds, using EleutherAI/gpt-neo-1.3B]\n",
            "this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things about this one: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things about this one: negative \n",
            " I love the music: positive \n",
            " I've heard not so great things about the film: negative\n",
            "\n",
            "Awards\n",
            "\n",
            "\n",
            "\n",
            "this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things about this one: negative \n",
            " I just like the movie: positive \n",
            " I love this movie: positive \n",
            " I just like the movie: positive \n",
            " I love this movie: positive \n",
            "\n",
            "Category:2013 films\n",
            "Category:2013 horror films\n",
            "Category\n",
            "\n",
            "\n",
            "this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " this movie was great: positive \n",
            " one of the best films of the year: positive \n",
            " just plain awful: negative \n",
            " I would not see this one again: negative \n",
            " I love this film: positive \n",
            " I've heard not so great things about this one: negative \n",
            " I don't know this movie well at all: positive \n",
            " I would not be able to enjoy this movie for very long: positive \n",
            " This is a big, heavy movie: positive \n",
            " I've heard not so great things\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "time_start = time.time()\n",
        "\n",
        "q = few_shot_string\n",
        "\n",
        "# q = \"Hello, I'm a language model\"\n",
        "resp = generator(q, max_new_tokens=50, num_return_sequences=num_return)\n",
        "\n",
        "time_end = time.time()\n",
        "\n",
        "print(f\"[{time_end-time_start:3.2f} seconds, using {model_string}]\")\n",
        "\n",
        "for i, gen in enumerate(resp):\n",
        "  print(gen[gen_text_key])\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMTBW-nn_zsr"
      },
      "source": [
        "# Interactive using Gradio\n",
        "- [components doc](https://gradio.app/docs/)\n",
        "\n",
        "**Warning**\n",
        "\n",
        "When using a few-shot prompt: smaller models seem to be particularly sensitive to extra blanks at the end of the final line (the one *without* the answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9ac_Ws-9_1sQ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Use generator from pipeline above\n",
        "\n",
        "def generate(prompt, num_return, len_return):\n",
        "    resp = generator(prompt, max_new_tokens=len_return, num_return_sequences=num_return)\n",
        "\n",
        "    # Create output string\n",
        "    out = \"\\n\\n\".join( [ r[gen_text_key] for r in  resp ])\n",
        "\n",
        "    return out\n",
        "\n",
        "iface = gr.Interface(\n",
        "          generate,\n",
        "          inputs=[\n",
        "              gr.Textbox(type=\"text\",\n",
        "                         value=few_shot_string,\n",
        "                         label=\"Type your input here:\", show_label=True\n",
        "                         ),\n",
        "              gr.Number(value=num_return,\n",
        "                        precision=0,\n",
        "                        label=\"# of outputs to generate\", show_label=True\n",
        "                        ),\n",
        "              gr.Number(value=len_return,\n",
        "                        precision=0,\n",
        "                        label=\"length of output\", show_label=True\n",
        "                        ),\n",
        "          ],\n",
        "          outputs=[\n",
        "              gr.Textbox(type=\"text\", label=\"Output: \", show_label=True)\n",
        "          ],\n",
        "          title=f\"Text completion using {model_string}\"\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "AhONjs9UEPif",
        "outputId": "f7eb6cc3-4760-41e5-d2c6-566e99820989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://259fd75f815860fe2c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://259fd75f815860fe2c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "iface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "HuggingFace",
      "language": "python",
      "name": "huggingface"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}