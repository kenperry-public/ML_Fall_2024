{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\n",
       "\\newcommand{\\x}{\\mathbf{x}}\n",
       "\\newcommand{\\tx}{\\tilde{\\x}}\n",
       "\\newcommand{\\y}{\\mathbf{y}}\n",
       "\\newcommand{\\b}{\\mathbf{b}}\n",
       "\\newcommand{\\c}{\\mathbf{c}}\n",
       "\\newcommand{\\e}{\\mathbf{e}}\n",
       "\\newcommand{\\z}{\\mathbf{z}}\n",
       "\\newcommand{\\h}{\\mathbf{h}}\n",
       "\\newcommand{\\u}{\\mathbf{u}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\w}{\\mathbf{w}}\n",
       "\\newcommand{\\V}{\\mathbf{V}}\n",
       "\\newcommand{\\W}{\\mathbf{W}}\n",
       "\\newcommand{\\X}{\\mathbf{X}}\n",
       "\\newcommand{\\KL}{\\mathbf{KL}}\n",
       "\\newcommand{\\E}{{\\mathbb{E}}}\n",
       "\\newcommand{\\Reals}{{\\mathbb{R}}}\n",
       "\\newcommand{\\ip}{\\mathbf{{(i)}}}\n",
       "%\n",
       "% Test set\n",
       "\\newcommand{\\xt}{\\underline{\\x}}\n",
       "\\newcommand{\\yt}{\\underline{\\y}}\n",
       "\\newcommand{\\Xt}{\\underline{\\X}}\n",
       "\\newcommand{\\perfm}{\\mathcal{P}}\n",
       "%\n",
       "% \\ll indexes a layer; we can change the actual letter\n",
       "\\newcommand{\\ll}{l}\n",
       "\\newcommand{\\llp}{{(\\ll)}}\n",
       "%\n",
       "\\newcommand{Thetam}{\\Theta_{-0}}\n",
       "\n",
       "% CNN\n",
       "\\newcommand{\\kernel}{\\mathbf{k}} \n",
       "\\newcommand{\\dim}{d}\n",
       "\\newcommand{\\idxspatial}{{\\text{idx}}}\n",
       "\\newcommand{\\summaxact}{\\text{max}}\n",
       "\\newcommand{idxb}{\\mathbf{i}}\n",
       "%\n",
       "%\n",
       "\n",
       "% RNN\n",
       "% \\tt indexes a time step\n",
       "\\newcommand{\\tt}{t}\n",
       "\\newcommand{\\tp}{{(\\tt)}}\n",
       "%\n",
       "%\n",
       "\n",
       "% LSTM\n",
       "\\newcommand{\\g}{\\mathbf{g}}\n",
       "\\newcommand{\\remember}{\\mathbf{remember}}\n",
       "\\newcommand{\\save}{\\mathbf{save}}\n",
       "\\newcommand{\\focus}{\\mathbf{focus}}\n",
       "%\n",
       "%\n",
       "% NLP\n",
       "\\newcommand{\\Vocab}{\\mathbf{V}}\n",
       "\\newcommand{\\v}{\\mathbf{v}}\n",
       "\\newcommand{\\offset}{o}\n",
       "\\newcommand{\\o}{o}\n",
       "\\newcommand{\\Emb}{\\mathbf{E}}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\loss}{\\mathcal{L}}\n",
       "\\newcommand{\\cost}{\\mathcal{L}}\n",
       "%\n",
       "%                     \n",
       "\\newcommand{\\pdata}{p_\\text{data}}\n",
       "\\newcommand{\\pmodel}{p_\\text{model}}\n",
       "%\n",
       "% SVM\n",
       "\\newcommand{\\margin}{{\\mathbb{m}}}\n",
       "\\newcommand{\\lmk}{\\boldsymbol{\\ell}}\n",
       "%\n",
       "%\n",
       "% Functions with arguments\n",
       "\\def\\xsy#1#2{#1^#2}\n",
       "\\def\\rand#1{\\tilde{#1}}\n",
       "\\def\\randx{\\rand{\\x}}\n",
       "\\def\\randy{\\rand{\\y}}\n",
       "\\def\\trans#1{\\dot{#1}}\n",
       "\\def\\transx{\\trans{\\x}}\n",
       "\\def\\transy{\\trans{\\y}}\n",
       "%\n",
       "\\def\\argmax#1{\\underset{#1} {\\operatorname{argmax}} }\n",
       "\\def\\argmin#1{\\underset{#1} {\\operatorname{argmin}} }\n",
       "\\def\\max#1{\\underset{#1} {\\operatorname{max}} }\n",
       "\\def\\min#1{\\underset{#1} {\\operatorname{min}} }\n",
       "%\n",
       "\\def\\pr#1{\\mathcal{p}(#1)}\n",
       "\\def\\prc#1#2{\\mathcal{p}(#1 \\; | \\; #2)}\n",
       "\\def\\cnt#1{\\mathcal{count}_{#1}}\n",
       "\\def\\node#1{\\mathbb{#1}}\n",
       "%\n",
       "\\def\\loc#1{{\\text{##} {#1}}}\n",
       "%\n",
       "\\def\\OrderOf#1{\\mathcal{O}\\left( {#1} \\right)}\n",
       "%\n",
       "% Expectation operator\n",
       "\\def\\Exp#1{\\underset{#1} {\\operatorname{\\mathbb{E}}} }\n",
       "%\n",
       "% VAE\n",
       "\\def\\prs#1#2{\\mathcal{p}_{#2}(#1)}\n",
       "\\def\\qr#1{\\mathcal{q}(#1)}\n",
       "\\def\\qrs#1#2{\\mathcal{q}_{#2}(#1)}\n",
       "%\n",
       "% Reinforcement learning\n",
       "\\newcommand{\\Actions}{{\\mathcal{A}}} \n",
       "\\newcommand{\\actseq}{A}\n",
       "\\newcommand{\\act}{a}\n",
       "\\newcommand{\\States}{{\\mathcal{S}}}   \n",
       "\\newcommand{\\stateseq}{S}  \n",
       "\\newcommand{\\state}{s}\n",
       "\\newcommand{\\Rewards}{{\\mathcal{R}}}\n",
       "\\newcommand{\\rewseq}{R}\n",
       "\\newcommand{\\rew}{r}\n",
       "\\newcommand{\\transp}{P}\n",
       "\\newcommand{\\statevalfun}{v}\n",
       "\\newcommand{\\actvalfun}{q}\n",
       "\\newcommand{\\disc}{\\gamma}\n",
       "%\n",
       "%\n",
       "\\newcommand{\\floor}[1]{\\left\\lfloor #1 \\right\\rfloor}\n",
       "\\newcommand{\\ceil}[1]{\\left\\lceil #1 \\right\\rceil}\n",
       "%\n",
       "%\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Latex_macros.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# My standard magic !  You will see this in almost all my notebooks.\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "\n",
    "import cnn_helper\n",
    "%aimport cnn_helper\n",
    "cnnh = cnn_helper.CNN_Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction: Beyond the Feature dimension\n",
    "\n",
    "## Adding \"shape\" to an example\n",
    "\n",
    "Thus far, the data examples we have been using are vectors\n",
    "- the only dimension is the \"feature\" dimension\n",
    "- for example, the names of the features in the feature dimension are `Price, Volume, Open, Close`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The diagram shows (our typical, up to now: 0 non-feature dimensional) feature vector $\\x$ matched against pattern $\\kernel$\n",
    "- where the feature dimension is length $3$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Zero non-feature dimensions, length 3 feature dimension</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/conv_0d.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In this module, we extend \"pattern matching\" to includes examples that have \"shape\"\n",
    "- an arrangement of *elements*, each element being a vector of features\n",
    "\n",
    "The arrangement of elements will be described by\n",
    "- dimensions beyond the feature dimension\n",
    "\n",
    "For example\n",
    "- a timeseries\n",
    "    - elements arranged as a *sequence* via a single non-feature dimension called \"time\"\n",
    "    - each element is a vector with features `Price, Volume, Open, Close`\n",
    "- a pixel grid\n",
    "    - elements arranged in two dimensional space with non-feature dimensions called \"row\" and \"column\"\n",
    "    - each element has the features `Red, Green, Blue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider an example with\n",
    "- one non-feature dimension of length $2$ (horizontal axis)\n",
    "$$\n",
    "\\dim_{1} = 2\n",
    "$$\n",
    "\n",
    "- three features \n",
    "$$\n",
    "n = 3\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>One non-feature dimension of length 2, feature dimension of length 3</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/conv_1d_example_only.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "The example $\\x$ has two *elements* \n",
    "- an *element* is a vector with *no* non-feature dimensions\n",
    "- labeled $\\x_{[0]}$ and $\\x_{[1]}$\n",
    "- each of length $n$\n",
    "\n",
    "This is a one-dimensional (counting only non-feature dimensions) example.\n",
    "\n",
    "You might see an example like this when dealing with data from Equity pricing\n",
    "- features: `Close Price, Open Price, Volume`\n",
    "- the elements might correspond to\n",
    "    - different equities\n",
    "    - different dates\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can generalize to more than a single non-feature dimension\n",
    "\n",
    "For example\n",
    "- an $(H \\times W)$ image has two non-feature dimensions with lengths\n",
    "$$\n",
    "\\dim_{1} = H, \\dim_{2} = W\n",
    "$$\n",
    "\n",
    "with $H * W$ elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In general\n",
    "- if there are $N$ non-feature dimensions\n",
    "    - where the length of the $i^{th}$ dimensions is denoted $\\dim{}_i$\n",
    "- we can index an element by a vector of length $N$ in\n",
    "$$\n",
    "[1:\\dim_{1}] \\times[1:\\dim_{2}] \\times \\ldots [1:\\dim_{N} ]\n",
    "$$\n",
    "- an index identifies a specific *location* in the non-feature dimensions\n",
    "\n",
    "There are $\\prod_{i=1}^N { \\dim_{i} }$ elements in the example\n",
    "- one at each location\n",
    "- where the location is specified by its index in the non-feature dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pattern matching examples with shape\n",
    "\n",
    "How does pattern matching work in the presence of non-feature dimensions ?\n",
    "\n",
    "Consider an example $\\x$ with $N$ non-feature dimensions of lengths \n",
    "$$\n",
    "\\dim_{1}, \\ldots, \\dim_{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will define a pattern $\\kernel$ to have *identical* shape as the example\n",
    "- same number $N$ of non-feature dimensions\n",
    "- same lengths of these dimensions\n",
    "    - we will subsequently allow the lengths to be shorter\n",
    "- same number of features\n",
    "- define elements of the pattern similar to elements of the example\n",
    "    - there are $\\prod_{i=1}^N { \\dim_{i} }$ elements in the pattern\n",
    "    \n",
    "**Remember**\n",
    "\n",
    "- The shape of a \"full\" pattern is the same as the shape of an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Terminology**\n",
    "\n",
    "In the literature of Convolutions, some familiar concepts are described with different words\n",
    "- A pattern is also referred to as a *kernel*\n",
    "- The feature dimensions is also referred to as the *channel* dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example $\\x$ along with pattern $\\kernel$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>One non-feature dimension of length 2, feature dimension of length 3</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/conv_1d.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now generalize the dot product to accommodate non-feature dimensions\n",
    "\n",
    "$$\n",
    "\\x \\cdot \\kernel = \\sum_{\\text{idx} \\in [1:\\dim_{1}] \\times[1:\\dim_{2}] \\times \\ldots [1:\\dim_{N} ] }\n",
    "{ \\x_\\text{idx} \\cdot \\kernel_\\text{idx} }\n",
    "$$\n",
    "\n",
    "That is\n",
    "- we perform the dot product of feature-only vectors\n",
    "- of elements in $\\x$ and $\\kernel$ with identical indices\n",
    "- and sum them up\n",
    "\n",
    "$$\n",
    "\\x_{[0]} \\cdot \\kernel _{[0]} \\, + \\, \\x_{[1]} \\cdot \\kernel _{[1]}\n",
    "$$\n",
    "\n",
    "So the *scalar* result may be interpreted\n",
    "- the dot product of each element matches similarity of corresponding elements\n",
    "- the sum creates a kind of \"average similarity\" across the elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visualize the generalized dot product with a more familiar example\n",
    "- recognizing a smiley face in a 2D image\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Two non-feature dimensions, each of length 8, feature dimension of length `<br> One pattern</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape_one_full_pattern.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the above diagram\n",
    "- the example has non-spatial dimensions $\\dim_{1} = \\dim_{2} = 8$\n",
    "- one feature: $n = 1$\n",
    "- there is one pattern\n",
    "    - non-feature and feature dimensions identical to example\n",
    "    - a \"full\" pattern\n",
    "- the number of features of the output\n",
    "    - equals the number of patterns\n",
    "    - one output feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple output features: matching against multiple patterns\n",
    "\n",
    "The above matches an example $\\x$ with a single pattern\n",
    "- to create a single output feature\n",
    "\n",
    "We can create a *second* output feature by adding a second pattern\n",
    "- similar to how a Fully Connected layer creates multiple features via multiple patterns\n",
    "- resulting in an output vector consisting of 2 features\n",
    "    - a no non-feature dimensions\n",
    "\n",
    "In general, we can add many patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The diagram shows a \n",
    "- 1 non-feature dimension (of length 2) vector $\\x$ \n",
    "$\\dim_{1} = 2$\n",
    "\n",
    " - with feature dimension length $3$\n",
    " $$\n",
    " n = 3\n",
    " $$\n",
    "- matched against 2 patterns $\\kernel_0, \\kernel_1$\n",
    "    - pattern $\\kernel_i$ has elements denoted $\\kernel_{i, [0]}$ and $\\kernel_{i, [1]}$ \n",
    "- resulting in an output with 2 features\n",
    "    - the first measuring the intensity of the match with the first pattern\n",
    "    - the second measuring the intensity of the match with the second pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>One non-feature dimension of length 2, feature dimension of length 3<br> Two patterns</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/conv_1d_2features.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Visualizing the dot product with our \"smiley face\" example once more\n",
    "- second pattern is a weaker match with the  example than first pattern\n",
    "- two patterns means output has two features\n",
    "\n",
    "**Remember**\n",
    "\n",
    "The number of output features is equal to the number of kernels/patterns\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Two non-feature dimensions, each of length 8, feature dimension of length 1<br> Two patterns</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape_two_full_pattern.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Patterns smaller than examples\n",
    "\n",
    "Thus far, the non-feature dimensions of the example and pattern\n",
    "- are identical in number $N$\n",
    "- and lengths $\\dim_{1}, \\ldots \\dim_{N}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That is\n",
    "- we seek to match a pattern against the entire non-feature dimensions of the input.\n",
    "\n",
    "Consider the following pattern which is of identical dimension to the input\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Pattern spanning entire non-feature dimensions, single feature</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape_1.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "In fact: this pattern is identical to the input and matches it perfectly !\n",
    "- the generalized dot product of the input and the pattern results in a high activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But what about examples similar to this one but\n",
    "- shifted right/left or up/down\n",
    "    - we week \"translational invariance\"\n",
    "- a smaller smile\n",
    "- different distance between the eyes\n",
    "\n",
    "The pattern would not be as good a match\n",
    "- lower activation\n",
    "- even though the \"meaning\" of the similar input is the same as the original: \"smiling face\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "It might be useful to be able to match\n",
    "- smaller patterns\n",
    "- that occur *somewhere* in the example\n",
    "- rather than a pattern that matches the entire example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the following smaller $(2 \\times 2)$ patterns\n",
    "- one matching an eye\n",
    "- one matching the left corner of a mouth\n",
    "- one matching the right corner of a mouth\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Convolution: 1 input feature to 3 output features</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape_pattern_only.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Does the first pattern (the eye) occur *somewhere* in $\\x$ ?\n",
    "\n",
    "We define an operation to answer that questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution: visual explanation\n",
    "\n",
    "It will be easier to describe the operation via a picture\n",
    "- and follow up with a more precise formulation\n",
    "\n",
    "We match an \"eye\" pattern\n",
    "- against every sub-region of the example\n",
    "- of identical size to the pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What does it mean to match the pattern against every \"sub-region\" ?\n",
    "\n",
    "Imagine placing the pattern to overlap the upper left corner (one region)\n",
    "- match the pattern against this sub-region\n",
    "- this measures the intensity of the match at this particular sub-region\n",
    "\n",
    "Now move this pattern (e.g., one pixel right/left or up/down)\n",
    "- this defines another sub-region against which the pattern is matched\n",
    "- the match measures the intensity of the match at this particular sub-region\n",
    "\n",
    "Repeat this matching process against every sub-region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The result\n",
    "- has shape (in the non-feature dimensions) that is the same as the example's shape (in the non-feature dimensions)\n",
    "- whose value is an intensity\n",
    "\n",
    "A picture will make this more concrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Convolution: 1 input feature to 1 output feature</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape_one_pattern.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In words:\n",
    "- the \"small\" pattern $\\kernel$  (less than full non-feature dimension size of the example)\n",
    "- is matched against each \"sub-region\" of $\\x$\n",
    "    - where a sub-region has non-feature dimensions that are the same as the kernel\n",
    "    - is centered at one index $\\text{idx}$ in the set of element indices of $\\x$\n",
    "- producing  a scalar value\n",
    "    - indicating the intensity of the match of the small pattern with the part centered at $\\text{idx}$ \n",
    "- the output\n",
    "    - has the same non-feature dimensions as the input example\n",
    "    - has one feature\n",
    "        - the match intensity\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The output is called a *feature map*\n",
    "- same non-feature dimension \"shape\" as example\n",
    "     - $N$ non-feature dimensions of lengths $\\dim_{1}, \\ldots \\dim_{N}$\n",
    "- maps the intensity of the match of the pattern\n",
    "- when the pattern is centered at each index in the set of indices of the example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And, just as before\n",
    "- we can use multiple patterns\n",
    "- to get multiple output features\n",
    "\n",
    "Each output feature $\\y_{\\llp, j}$\n",
    "- is a feature map for the $j^{th}$ pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Convolution: 1 input feature to 3 output features</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hopefully you can see why small patterns are useful\n",
    "- they result in feature maps that locate the presences of the small pattern\n",
    "- at any location in the non-feature dimensions of the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution: detailed explanation\n",
    "\n",
    "Define operation $\\text{Conv}$ with two arguments\n",
    "- an example $\\x$ with \n",
    "    - $N$ non-feature dimensions of lengths $\\dim_{1}, \\ldots \\dim_{N}$\n",
    "    - a feature dimension of length $n$\n",
    "- a pattern $\\kernel$ with\n",
    "     - $N$ non-feature dimensions of lengths $\\dim'_{1}, \\ldots \\dim'_{N}$\n",
    "         - such that\n",
    "     $$ \\dim'_{i} \\le \\dim_{i}: \\, 1 \\le i \\le N $$\n",
    "     - a feature dimension of length $n$\n",
    "\n",
    "The $\\kernel$ is able to be *smaller* than $\\x$ in each non-feature dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\text{Conv}$ produces an output $\\y$\n",
    "- with $N$ non-feature dimensions of lengths $\\dim_{1}, \\ldots \\dim_{N}$\n",
    "    - same as the $N$ non-feature dimensions of $\\x$\n",
    "- a feature dimension of length 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We define $\\y = \\text{Conv}(\\x, \\kernel)$ by the output it produces\n",
    "- at each index in the set of indexes of the elements in $\\x$\n",
    "$$\n",
    "\\text{idx} \\in [1:\\dim_{1}] \\times[1:\\dim_{2}] \\times \\ldots [1:\\dim_{N} ]\n",
    "$$\n",
    "\n",
    "Let\n",
    "- $\\text{SubRegion}(\\x, \\text{idx}, \\kernel)$\n",
    "    - denote a sub-region of $\\x$\n",
    "    - centered at index $\\text{idx}$\n",
    "    - with non-feature dimensions identical to those of $\\kernel$\n",
    "    - and all $n$ features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then\n",
    "$$\n",
    "\\y_\\text{idx} = \\text{SubRegion}(\\x, \\text{idx}, \\kernel) \\cdot \\kernel\n",
    "$$\n",
    "\n",
    "So \n",
    "- the output feature map $\\y$\n",
    "- has $\\dim_{1} * \\dim_{2} * \\ldots \\dim_{N}$ elements\n",
    "- letting $\\text{idx}$ represent the index of just one element\n",
    "- $\\y_\\text{idx}$ is the result of matching\n",
    "    - pattern $\\kernel$\n",
    "    - with a the sub-region (of size matching $\\kernel$) of the example\n",
    "    - centered at $\\text{idx}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When can generalize this to an *multiple* patterns.\n",
    "\n",
    "The above definition defines *one* feature map corresponding to the match against a single pattern.\n",
    "\n",
    "In the presence of multiple patterns $K$\n",
    "- output $\\y$ has feature dimension of length $K$\n",
    "- $\\y_{\\text{idx}, j}$ is the feature map corresponding to the $j^{th}$ pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Convolutional Neural Network (CNN) layer type\n",
    "\n",
    "We define a Neural Network Layer type\n",
    "- called the *Convolutional Neural Network (CNN)*\n",
    " to implement the $\\text{Conv}$ operator against multiple patterns.\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Convolution Layer: 1 input feature to 3 output features</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/Conv2d_multifeature_shape.png\" width=80%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the diagram below we show a *Convolutional Layer*\n",
    "- involving $3$ \"small\" patterns\n",
    "- \n",
    "that is performed by a CNN Layer type that is layer $\\ll$ of a Sequential NN\n",
    "\n",
    "- the input is $\\y_{(\\ll-1)}$ (the output of layer $(\\ll-1)$ in a multi-layer NN)\n",
    "- there are 3 patterns with non-spatial dimensions $(2 \\times 2)$\n",
    "    - $\\kernel_{\\llp,1}$ is the pattern for an \"eye\"\n",
    "    - $\\kernel_{\\llp,2}$ and $\\kernel_{\\llp,3}$ are patterns for the left/right corner of the smile\n",
    "- the output feature map $\\y_\\llp$ (the layer output)\n",
    "    - has non-feature dimensions equal in number and length to those of $\\y_{(\\ll-1)}$\n",
    "    - shows the locations within input $\\y_{(\\ll-1)}$ where the pattern is matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional Neural Network (CNN) layer summary\n",
    "\n",
    "Consider input layer $(\\ll-1)$ with \n",
    "- $N$ spatial dimensions\n",
    "- $n_{(\\ll-1)}$ feature maps/channels\n",
    "$$\n",
    "|| \\y_{(\\ll-1)} || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_{(\\ll-1)} )\n",
    "$$\n",
    "\n",
    "Convolutional Layer $\\ll$ will apply a Convolution that \n",
    "- preserves the spatial dimensions\n",
    "- but *may* change the number of features\n",
    "\n",
    "$$\n",
    "|| \\y_\\llp || = (\\dim_{(\\ll-1),1} \\times \\dim_{(\\ll-1),2} \\times \\ldots \\dim_{(\\ll-1),N} \\times n_\\llp )\n",
    "$$\n",
    "\n",
    "using $n_\\llp$ kernels\n",
    "- each of dimension \n",
    "$$(f_{\\llp. 1} \\times f_{\\llp, 2} \\times \\ldots f_{\\llp. N} \\times n_{(\\ll-1)})$$\n",
    "\n",
    "Typically:\n",
    "$$\n",
    "f_{\\llp,i} = f_\\llp \\text{ (a constant) for  } 1 \\le i \\le N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We summarize the key points\n",
    "\n",
    "**Reminders**\n",
    "\n",
    "Inputs\n",
    "- The number $N$ of non-feature dimensions\n",
    "    - of the kernel and example are the same\n",
    "- The *length* of each non-feature dimension of the kernel\n",
    "    - is less than or equal to the length of the corresponding dimension of the example\n",
    "- The feature dimension's length of the kernel and example are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Outputs\n",
    "- The number of output features equals the number of kernels\n",
    "- The length of the output's non-feature dimensions is the same as the length of the corresponding dimension of the example\n",
    "    - this is true only with \"same\" padding\n",
    "    - without full padding: $\\lfloor \\frac{f}{2} \\rfloor$ elements may be lost from each end of a dimension\n",
    "        - where $f$ is length of each kernel non-feature dimension\n",
    "\n",
    "Convolution (with full padding)\n",
    "- changes the length of the feature dimension\n",
    "\n",
    "**Key point**\n",
    "\n",
    "A Convolutional Layer \n",
    "- preserves *non-feature* dimensions (assuming \"same\" padding)\n",
    "- **changes** the number of features from $n_{(\\ll-1)}$ to $n_\\llp$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How is the Feature dimension different from non-feature dimensions ?\n",
    "\n",
    "The feature dimension has some key differences from the non-feature dimensions\n",
    "- the indices of the feature dimension are *unordered*\n",
    "    - permuting the features \n",
    "        - from `Price, Volume, Open, Close` \n",
    "        - to `Open, Close, Price, Volume` \n",
    "    - does not change the meaning of the example\n",
    "    \n",
    "In contrast the *non-feature* dimensions are at least *partially ordered*\n",
    "- permuting the order of a non-feature dimensions *changes the meaning* of an example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider\n",
    "- the indices of the temporal dimension are totally ordered\n",
    "    - reversing the indices makes time flow backwards rather than forwards\n",
    "- the indices of the spatial dimension are (at least, partially) *ordered*\n",
    "    - given an image of a face\n",
    "        - the eyes are located above the mouth\n",
    "        - in a horizontal orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- words in a sentence are ordered\n",
    "$$\n",
    "\\begin{array} \\\\\n",
    "\\x &  =  & [ \\text{Machine, Learning, is, easy, not, hard } ] \\\\\n",
    "\\x [ \\text{perm} ] & = &  [ \\text{Machine, Learning, is, hard, not, easy} ]  \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "    - very different meanings\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Convolution respects the relative order of the elements of the example.\n",
    "\n",
    "Layers that operate purely on the feature dimensions do not respect the order of features.\n",
    "\n",
    "For example\n",
    "- A `Dense` layer will compute the *same dot-product* of features and weights\n",
    "- as long they both obey the same order\n",
    "\n",
    "$$\n",
    "\\x \\cdot \\w =  \\x [ \\text{perm} ] \\cdot \\w[ \\text{perm} ] \n",
    "$$\n",
    "even though $\\x$ and $ \\x [ \\text{perm} ]$ have much different meanings.\n",
    "\n",
    "That is: order is not respected by the feature dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is generally problematic to try to use the feature dimension as a replacement for a non-feature dimensions.\n",
    "- when ordering is important\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>Feature only vector</center></th>\n",
    "        <th><center>One feature plus one temporal dimension</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/words_in_features.png\" width=90%></td>\n",
    "        <td><img src=\"images/words_in_sequence.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where do the patterns come from ? Training a CNN\n",
    "\n",
    "Hopefully you understand how patterns (kernels) are \"feature recognizers\".\n",
    "\n",
    "But you may be wondering: how do we determine the weights in each kernel ?\n",
    "\n",
    "Answer: a Convolutional Layer is \"just another\" layer in a multi-layer network\n",
    "- The kernels are just weights (like the weights in Fully Connected layers)\n",
    "- We solve for all the weights $\\W$ in the multi-layer network in the same way\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The answer is: exactly as we did in Classical Machine Learning\n",
    "- Define a loss function that is parameterized by $\\W$: \n",
    "$$\\loss = L(\\hat{\\y},\\y; \\W)$$\n",
    "\n",
    "- The kernel weights are just part of $\\W$\n",
    "- Our goal is to find $\\W^*$ the \"best\" set of weights\n",
    "$$\n",
    "\\W^* = \\argmin{W} L(\\hat{\\y},\\y; \\W)\n",
    "$$\n",
    "- Using Gradient Descent !\n",
    "\n",
    "In other words: their is nothing special about finding the \"best\" kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conv1d: the under-appreciated convolution\n",
    "\n",
    "CNN's seem to be most associated with *image* input\n",
    "- Two non-feature dimensions\n",
    "\n",
    "It's worth pointing out how a one-dimensional (single non-feature dimension) convolution an be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time Series\n",
    "\n",
    "Let the single non-feature dimensions denote time.\n",
    "- I will use subscript $\\tt$ to index into the elements\n",
    "\n",
    "Suppose \n",
    "- Example $n = 1$ features: `Volume`\n",
    "- single kernel\n",
    "    - $f = 3$: length of kernel\n",
    "    \n",
    "So the output $\\y$ will\n",
    "- be a timeseries of length equal to the example\n",
    "- have a single feature\n",
    "    - one kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then by definition of convolution (writing out the dot product for each index)\n",
    "\n",
    "$$\n",
    "\\y_{\\tp,1} = \\sum_{o=-1}^{o=+1} { \\x_{(\\tt + o,)1} * \\kernel_{ o + 1, 1 }}\n",
    "$$\n",
    "\n",
    "The convolution is just a *moving average* !\n",
    "- with *learned* weights: the kernel values\n",
    "\n",
    "Note the subscript \"1\" to refer to the single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A word of warning\n",
    "- $\\y_{\\tp,1}$ references a value that occurs after time $\\tt$\n",
    "    -  $\\y_{(\\tt+1),1}$\n",
    "\n",
    "Depending on your task\n",
    "- this may be dis-allowed\n",
    "- equivalent to \"peeking into the future\"\n",
    "\n",
    "*Causal* convolution is a restriction on convolution to prevent looking ahead into the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLP: n-grams\n",
    "\n",
    "We have not yet covered Natural Language Processing (NLP)\n",
    "- but we can give some intuition \n",
    "- on how one dimensional Convolution may be used\n",
    "\n",
    "Since words (really: tokens) are *categorical* values\n",
    "- we need to \"numericalize\" them\n",
    "- turn into vectors\n",
    "    - OHE vectors, of length equal to number of tokens in vocabulary\n",
    "    - dense vectors: Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We use $n$ to denote the number of features of the vector that encode tokens.\n",
    "\n",
    "Below we illustrate\n",
    "- example that is a sequence of words \n",
    "    - elements are indexed by time/position\n",
    "- $n$ is length of the vector encoding of a token\n",
    "- Single Kernel\n",
    "    - $f = 2 $\n",
    "- No padding\n",
    "    - so output sequence loses one element at start  of sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>NLP: Conv1d<br>single kernel</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/NLP_conv1d.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The one-dimensional convolution\n",
    "- coverts two consecutive tokens\n",
    "- into a single vector\n",
    "\n",
    "This is called creating a *bi-gram*\n",
    "- if we combine $f$ tokens, we call it an *f-gram*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "f-grams are interesting and useful because\n",
    "- sometimes $f$ consecutive tokens\n",
    "- denote a new *semantically meaningful* concept\n",
    "- that is very different from the individual tokens\n",
    "\n",
    "For example\n",
    "- \"Machine Learning\"\n",
    "- \"New York City\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Below we expand this to multiple output features\n",
    "- each pattern is \"looking for\" (has maximum scalar dot product)\n",
    "- the concept highlighted in red\n",
    "\n",
    "<br>\n",
    "<table>\n",
    "    <tr>\n",
    "        <th><center>NLP: Conv1d<br>multiple kernel</center></th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"images/NLP_conv1d_multi_kernel.png\" width=90%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
